{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/co-dutt1/.conda/envs/pytorch/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from scipy.spatial import distance\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disable_module(module):\n",
    "    for p in module.parameters():\n",
    "        p.requires_grad = False\n",
    "        \n",
    "def enable_module(module):\n",
    "    for p in module.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "\n",
    "def check_tunable_params(model, verbose=True):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            if(verbose):\n",
    "                print(name)\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.5f}\"\n",
    "    )\n",
    "\n",
    "    return trainable_params, all_param\n",
    "\n",
    "def create_mapping(model, vector):\n",
    "    mapping = {}\n",
    "    i = 0\n",
    "\n",
    "    for name_p,p in model.named_parameters():\n",
    "        if '.attn.' in name_p or 'attention' in name_p:\n",
    "            mapping[name_p] = vector[i]\n",
    "            i += 1\n",
    "        else:\n",
    "            p.requires_grad = False\n",
    "            \n",
    "    return mapping\n",
    "\n",
    "def sort_dict(dict, descending=False):\n",
    "    sorted_dict = dict(sorted(dict.items(), key=lambda item: item[1], reverse=descending))\n",
    "    \n",
    "    return sorted_dict\n",
    "\n",
    "def get_modules_from_vector(vector, model):\n",
    "    trainable_blocks = []\n",
    "    frozen_blocks = []\n",
    "    \n",
    "    trainable_blocks = np.where(np.array(vector) == 1)\n",
    "    frozen_blocks = np.where(np.array(vector) == 0)\n",
    "    \n",
    "    return trainable_blocks, frozen_blocks\n",
    "\n",
    "def get_model_for_bitfit(model):\n",
    "    trainable_components = ['bias', 'pooler.dense.bias', 'head'] \n",
    "\n",
    "    # Disale all the gradients\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False \n",
    "      \n",
    "    vector = []\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        for component in trainable_components:\n",
    "            if component in name:\n",
    "                vector.append(1)\n",
    "                param.requires_grad = True\n",
    "                break\n",
    "    \n",
    "    return vector\n",
    "\n",
    "def enable_from_vector(vector, model):\n",
    "    print(\"Vector: \", vector)\n",
    "    \n",
    "    disable_module(model)\n",
    "    \n",
    "    for idx, block in enumerate(model.blocks): \n",
    "    \n",
    "        if(vector[idx] == 1):\n",
    "            print(\"Enabling attention in Block {}\".format(idx))\n",
    "            enable_module(block.attn)\n",
    "        else:\n",
    "            #print(\"Disabling attention in Block {}\".format(idx))\n",
    "            disable_module(block.attn)\n",
    "\n",
    "def create_best_worst_vectors(df, k=10):\n",
    "    \n",
    "    best_df = df.sort_values(by=['Test Acc@1'], ascending=False).head(k).reset_index(drop=True)\n",
    "    worst_df = df.sort_values(by=['Test Acc@1'], ascending=True).head(k).reset_index(drop=True)\n",
    "\n",
    "    best_vector = np.array([0]*12)\n",
    "\n",
    "    for i in range(len(best_df)):\n",
    "        vector_path = best_df['Vector Path'][i]\n",
    "        vector = np.load(vector_path)\n",
    "        best_vector += vector\n",
    "\n",
    "    worst_vector = np.array([0]*12)\n",
    "\n",
    "    for i in range(len(worst_df)):\n",
    "        vector_path = worst_df['Vector Path'][i]\n",
    "        vector = np.load(vector_path)\n",
    "        worst_vector += vector\n",
    "\n",
    "    return best_vector, worst_vector\n",
    "\n",
    "def tune_blocks_random(model, mask, segment):\n",
    "\n",
    "    vector = []\n",
    "\n",
    "    for idx, block in enumerate(model.blocks):\n",
    "\n",
    "        if(mask is None):\n",
    "            bit = int(np.random.random(1)[0] > 0.5)\n",
    "        else:\n",
    "            bit = mask[idx]\n",
    "\n",
    "        if(bit == 1):\n",
    "            print(\"Enabling {} in Block {}\".format(segment, idx))\n",
    "            if(segment == 'attention'):\n",
    "                enable_module(block.attn)\n",
    "            elif(segment == 'layernorm'):\n",
    "                enable_module(block.norm1)\n",
    "                enable_module(block.norm2)\n",
    "\n",
    "            vector.append(1)\n",
    "        else:\n",
    "            print(\"Disabling {} in Block {}\".format(segment, idx))\n",
    "            if(segment == 'attention'):\n",
    "                disable_module(block.attn)\n",
    "            elif(segment == 'layernorm'):\n",
    "                disable_module(block.norm1)\n",
    "                disable_module(block.norm2)\n",
    "            \n",
    "            vector.append(0)\n",
    "    \n",
    "    if(mask is not None):\n",
    "        assert (mask == vector)\n",
    "        \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1.], requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_random_mask(mask_length):\n",
    "    #return np.random.randint(low=0, high=2, size=mask_length)\n",
    "    return nn.Parameter(torch.randint(low=0, high=2, size=(mask_length,), dtype=torch.float32), requires_grad=True)\n",
    "\n",
    "mask = create_random_mask(12)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss = torch.tensor([0.5], requires_grad=True)\n",
    "val_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = timm.create_model('vit_base_patch16_224', pretrained=False)\n",
    "# num_blocks = len(model.blocks)\n",
    "\n",
    "# disable_module(model)\n",
    "\n",
    "# mask = list(np.random.randint(low=0, high=2, size=num_blocks*4))\n",
    "# attn_params = []\n",
    "\n",
    "# for name_p,p in model.named_parameters():\n",
    "#     if '.attn.' in name_p or 'attention' in name_p:\n",
    "#         attn_params.append(p)\n",
    "\n",
    "# attn_params = [p for name_p, p in model.named_parameters() if '.attn.' in name_p or 'attention' in name_p]\n",
    "\n",
    "# for idx, p in enumerate(attn_params):\n",
    "#     if(mask[idx] == 1):\n",
    "#         p.requires_grad = True\n",
    "#     else:\n",
    "#         p.requires_grad = False\n",
    "\n",
    "# check_tunable_params(model, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/co-dutt1/rds/hpc-work/Layer-Masking/Experiment_Vectors/\"\n",
    "num_blocks = 12\n",
    "# for i in range(1, 76):\n",
    "#     vector = np.random.randint(low=0, high=2, size=num_blocks)\n",
    "#     np.save(path + \"random_vector_{}.npy\".format(i), vector)\n",
    "\n",
    "# 76th vector is for tuning all attention blocks\n",
    "# vector = np.array([1]*12)\n",
    "# np.save(path + \"random_vector_{}.npy\".format(76), vector)\n",
    "\n",
    "# PARAMETER LEVEL\n",
    "\n",
    "# path = \"/home/co-dutt1/rds/hpc-work/Layer-Masking/Experiment_Vectors_Parameter/\"\n",
    "# for i in range(1, 76):\n",
    "#     vector = np.random.randint(low=0, high=2, size=num_blocks*4)\n",
    "#     np.save(path + \"random_vector_{}.npy\".format(i), vector)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Attention Tuning (Block Level)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BreastUS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/co-dutt1/rds/hpc-work/Layer-Masking/'\n",
    "csv = base_path + 'vit_base/breastUS/' + '.csv'\n",
    "\n",
    "df = pd.read_csv(csv)\n",
    "#df['Vector Path'] = df['Vector Path'].apply(lambda x: os.path.join(base_path, x.split('/')[-1]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc = df['Test Acc@1'].mean()\n",
    "std_acc = df['Test Acc@1'].std()\n",
    "max_acc = df['Test Acc@1'].max()\n",
    "min_acc = df['Test Acc@1'].min()\n",
    "avg_train_percent = df['Train Percent'].mean()\n",
    "diff = max_acc - min_acc\n",
    "best_train_percent = df[df['Test Acc@1'] == max_acc]['Train Percent'].values[0]\n",
    "\n",
    "print(\"Mean Acc: \", mean_acc)\n",
    "print(\"Std Acc: \", std_acc)\n",
    "print(\"Max Acc: \", max_acc)\n",
    "print(\"Min Acc: \", min_acc)\n",
    "print(\"Avg Train Percent: \", avg_train_percent)\n",
    "print(\"Best Performance Train Percent: \", best_train_percent)\n",
    "print(\"Diff: \", diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower_threshold = df['Test Acc@1'].quantile(0.10)\n",
    "# upper_threshold = df['Test Acc@1'].quantile(0.90)\n",
    "\n",
    "# top_1_percent = df[df['Test Acc@1'] >= upper_threshold].reset_index(drop=True)\n",
    "# bottom_1_percent = df[df['Test Acc@1'] <= lower_threshold].reset_index(drop=True)\n",
    "\n",
    "# bottom_1_percent\n",
    "\n",
    "k = 10\n",
    "best_df = df.sort_values(by=['Test Acc@1'], ascending=False).head(k).reset_index(drop=True)\n",
    "worst_df = df.sort_values(by=['Test Acc@1'], ascending=True).head(k).reset_index(drop=True)\n",
    "\n",
    "print(len(best_df), len(worst_df))\n",
    "best_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_vector = np.array([0]*12)\n",
    "\n",
    "for i in range(len(best_df)):\n",
    "    vector_path = best_df['Vector Path'][i]\n",
    "    vector = np.load(vector_path)\n",
    "    best_vector += vector\n",
    "\n",
    "worst_vector = np.array([0]*12)\n",
    "\n",
    "for i in range(len(worst_df)):\n",
    "    vector_path = worst_df['Vector Path'][i]\n",
    "    vector = np.load(vector_path)\n",
    "    worst_vector += vector\n",
    "\n",
    "best_vector, worst_vector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many times was each block trained during 50 runs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See which blocks were activated the maximum number of times\n",
    "\n",
    "sum_vec = np.array([0]*12)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    vec = np.load(df['Vector Path'][i])\n",
    "    sum_vec += vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(sum_vec))\n",
    "\n",
    "plt.figsize=(20, 10)\n",
    "# Plot the bar graph\n",
    "plt.bar(indices, sum_vec)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Block Index')\n",
    "plt.ylabel('Number of Times Trainable')\n",
    "plt.xticks(list(range(0,12)))\n",
    "plt.yticks(list(range(0, max(sum_vec)+1)))\n",
    "plt.title('Bar Plot of the number of times each attention block was activated (in 50 runs) in a ViT-Base Model.')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Random_Attention_Block_Tuning_breastUS.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(best_vector))\n",
    "\n",
    "plt.figsize=(20, 10)\n",
    "# Plot the bar graph\n",
    "plt.bar(indices, best_vector, label='Best')\n",
    "plt.bar(indices, worst_vector, label='Worst')\n",
    "plt.legend()\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Block Index')\n",
    "plt.ylabel('Block Selection Count')\n",
    "plt.xticks(list(range(0,12)))\n",
    "plt.yticks(list(range(0, max(best_vector)+1)))\n",
    "plt.title('Comparing the attention block selection frequency for best and worst performing vectors.')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Selection_Comparison_BreastUS.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the best performing vectors tune later blocks more than the worst performing vectors."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FitzPatrick Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'fitzpatrick'\n",
    "base_path = '/home/co-dutt1/rds/hpc-work/Layer-Masking/'\n",
    "csv = base_path + 'vit_base/' + dataset + '/tune_attention_blocks_random_vit_base_0.0001.csv'\n",
    "\n",
    "df = pd.read_csv(csv)\n",
    "#df['Vector Path'] = df['Vector Path'].apply(lambda x: os.path.join(base_path, x.split('/')[-1]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc = df['Test Acc@1'].mean()\n",
    "std_acc = df['Test Acc@1'].std()\n",
    "max_acc = df['Test Acc@1'].max()\n",
    "min_acc = df['Test Acc@1'].min()\n",
    "avg_train_percent = df['Train Percent'].mean()\n",
    "best_train_percent = df[df['Test Acc@1'] == max_acc]['Train Percent'].values[0]\n",
    "diff = max_acc - min_acc\n",
    "\n",
    "print(\"Mean Acc: \", mean_acc)\n",
    "print(\"Std Acc: \", std_acc)\n",
    "print(\"Max Acc: \", max_acc)\n",
    "print(\"Min Acc: \", min_acc)\n",
    "print(\"Avg Train Percent: \", avg_train_percent)\n",
    "print(\"Best Performance Train Percent: \", best_train_percent)\n",
    "print(\"Difference (Max, Min): \", diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "best_df = df.sort_values(by=['Test Acc@1'], ascending=False).head(k).reset_index(drop=True)\n",
    "worst_df = df.sort_values(by=['Test Acc@1'], ascending=True).head(k).reset_index(drop=True)\n",
    "\n",
    "print(len(best_df), len(worst_df))\n",
    "best_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_vector = np.array([0]*12)\n",
    "\n",
    "for i in range(len(best_df)):\n",
    "    vector_path = best_df['Vector Path'][i]\n",
    "    vector = np.load(vector_path)\n",
    "    best_vector += vector\n",
    "\n",
    "worst_vector = np.array([0]*12)\n",
    "\n",
    "for i in range(len(worst_df)):\n",
    "    vector_path = worst_df['Vector Path'][i]\n",
    "    vector = np.load(vector_path)\n",
    "    worst_vector += vector\n",
    "\n",
    "best_vector, worst_vector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many times was each block selected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See which blocks were activated the maximum number of times\n",
    "\n",
    "sum_vec = np.array([0]*12)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    vec = np.load(df['Vector Path'][i])\n",
    "    sum_vec += vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(sum_vec))\n",
    "\n",
    "plt.figsize=(20, 10)\n",
    "# Plot the bar graph\n",
    "plt.bar(indices, sum_vec)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Block Index')\n",
    "plt.ylabel('Number of Times Trainable')\n",
    "plt.xticks(list(range(0,12)))\n",
    "plt.yticks(list(range(0, max(sum_vec)+1)))\n",
    "plt.title('Bar Plot of the number of times each attention block was activated (in 50 runs) in a ViT-Base Model.')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Random_Attention_Block_Tuning_{}.png\".format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(best_vector))\n",
    "\n",
    "plt.figsize=(20, 10)\n",
    "# Plot the bar graph\n",
    "plt.bar(indices, best_vector, label='Best')\n",
    "plt.bar(indices, worst_vector, label='Worst')\n",
    "plt.legend()\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Block Index')\n",
    "plt.ylabel('Block Selection Count')\n",
    "plt.xticks(list(range(0,12)))\n",
    "plt.yticks(list(range(0, max(best_vector)+1)))\n",
    "plt.title('Comparing the attention block selection frequency for best and worst performing vectors.')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Selection_Comparison_{}.png\".format(dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMDG Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'smdg'\n",
    "base_path = '/home/co-dutt1/rds/hpc-work/Layer-Masking/'\n",
    "csv = base_path + 'vit_base/' + dataset + '/tune_attention_blocks_random_vit_base_0.0001.csv'\n",
    "\n",
    "df = pd.read_csv(csv)\n",
    "#df['Vector Path'] = df['Vector Path'].apply(lambda x: os.path.join(base_path, x.split('/')[-1]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc = df['Test Acc@1'].mean()\n",
    "std_acc = df['Test Acc@1'].std()\n",
    "max_acc = df['Test Acc@1'].max()\n",
    "min_acc = df['Test Acc@1'].min()\n",
    "avg_train_percent = df['Train Percent'].mean()\n",
    "best_train_percent = df[df['Test Acc@1'] == max_acc]['Train Percent'].values[0]\n",
    "diff = max_acc - min_acc\n",
    "\n",
    "print(\"Mean Acc: \", mean_acc)\n",
    "print(\"Std Acc: \", std_acc)\n",
    "print(\"Max Acc: \", max_acc)\n",
    "print(\"Min Acc: \", min_acc)\n",
    "print(\"Avg Train Percent: \", avg_train_percent)\n",
    "print(\"Best Performance Train Percent: \", best_train_percent)\n",
    "print(\"Difference (Max, Min): \", diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "best_df = df.sort_values(by=['Test Acc@1'], ascending=False).head(k).reset_index(drop=True)\n",
    "worst_df = df.sort_values(by=['Test Acc@1'], ascending=True).head(k).reset_index(drop=True)\n",
    "\n",
    "print(len(best_df), len(worst_df))\n",
    "best_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_vector = np.array([0]*12)\n",
    "\n",
    "for i in range(len(best_df)):\n",
    "    vector_path = best_df['Vector Path'][i]\n",
    "    vector = np.load(vector_path)\n",
    "    best_vector += vector\n",
    "\n",
    "worst_vector = np.array([0]*12)\n",
    "\n",
    "for i in range(len(worst_df)):\n",
    "    vector_path = worst_df['Vector Path'][i]\n",
    "    vector = np.load(vector_path)\n",
    "    worst_vector += vector\n",
    "\n",
    "best_vector, worst_vector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many times was each block selected?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See which blocks were activated the maximum number of times\n",
    "\n",
    "sum_vec = np.array([0]*12)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    vec = np.load(df['Vector Path'][i])\n",
    "    sum_vec += vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(sum_vec))\n",
    "\n",
    "plt.figsize=(20, 10)\n",
    "# Plot the bar graph\n",
    "plt.bar(indices, sum_vec)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Block Index')\n",
    "plt.ylabel('Number of Times Trainable')\n",
    "plt.xticks(list(range(0,12)))\n",
    "plt.yticks(list(range(0, max(sum_vec)+1)))\n",
    "plt.title('Bar Plot of the number of times each attention block was activated (in 50 runs) in a ViT-Base Model.')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Random_Attention_Block_Tuning_{}.png\".format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(best_vector))\n",
    "\n",
    "plt.figsize=(20, 10)\n",
    "# Plot the bar graph\n",
    "plt.bar(indices, best_vector, label='Best')\n",
    "plt.bar(indices, worst_vector, label='Worst')\n",
    "plt.legend()\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Block Index')\n",
    "plt.ylabel('Block Selection Count')\n",
    "plt.xticks(list(range(0,12)))\n",
    "plt.yticks(list(range(0, max(best_vector)+1)))\n",
    "plt.title('Comparing the attention block selection frequency for best and worst performing vectors.')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Selection_Comparison_{}.png\".format(dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HAM10000 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'HAM10000'\n",
    "base_path = '/home/co-dutt1/rds/hpc-work/Layer-Masking/'\n",
    "vector_path = '/home/co-dutt1/rds/hpc-work/Layer-Masking/saved_vectors/vit_base/HAM10000/tune_attention_blocks_random_0.0001/'\n",
    "csv = base_path + 'vit_base/' + dataset + '/tune_attention_blocks_random_vit_base_0.0001.csv'\n",
    "\n",
    "df = pd.read_csv(csv)\n",
    "df['Vector Path'] = df['Vector Path'].apply(lambda x: os.path.join(vector_path, x.split('/')[-1]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc = df['Test Acc@1'].mean()\n",
    "std_acc = df['Test Acc@1'].std()\n",
    "max_acc = df['Test Acc@1'].max()\n",
    "min_acc = df['Test Acc@1'].min()\n",
    "avg_train_percent = df['Train Percent'].mean()\n",
    "best_train_percent = df[df['Test Acc@1'] == max_acc]['Train Percent'].values[0]\n",
    "diff = max_acc - min_acc\n",
    "\n",
    "print(\"Mean Acc: \", mean_acc)\n",
    "print(\"Std Acc: \", std_acc)\n",
    "print(\"Max Acc: \", max_acc)\n",
    "print(\"Min Acc: \", min_acc)\n",
    "print(\"Avg Train Percent: \", avg_train_percent)\n",
    "print(\"Best train percent: \", best_train_percent)\n",
    "print(\"Difference (Max, Min): \", diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "best_df = df.sort_values(by=['Test Acc@1'], ascending=False).head(k).reset_index(drop=True)\n",
    "worst_df = df.sort_values(by=['Test Acc@1'], ascending=True).head(k).reset_index(drop=True)\n",
    "\n",
    "print(len(best_df), len(worst_df))\n",
    "worst_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_vector = np.array([0]*12)\n",
    "\n",
    "for i in range(len(best_df)):\n",
    "    vector_path = best_df['Vector Path'][i]\n",
    "    vector = np.load(vector_path)\n",
    "    best_vector += vector\n",
    "\n",
    "worst_vector = np.array([0]*12)\n",
    "\n",
    "for i in range(len(worst_df)):\n",
    "    vector_path = worst_df['Vector Path'][i]\n",
    "    vector = np.load(vector_path)\n",
    "    worst_vector += vector\n",
    "\n",
    "best_vector, worst_vector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many times was each block selected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See which blocks were activated the maximum number of times\n",
    "\n",
    "sum_vec = np.array([0]*12)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    vec = np.load(df['Vector Path'][i])\n",
    "    sum_vec += vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(sum_vec))\n",
    "\n",
    "plt.figsize=(20, 10)\n",
    "# Plot the bar graph\n",
    "plt.bar(indices, sum_vec)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Block Index')\n",
    "plt.ylabel('Number of Times Trainable')\n",
    "plt.xticks(list(range(0,12)))\n",
    "plt.yticks(list(range(0, max(sum_vec)+1)))\n",
    "plt.title('Bar Plot of the number of times each attention block was activated (in 50 runs) in a ViT-Base Model.')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Random_Attention_Block_Tuning_{}.png\".format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(best_vector))\n",
    "\n",
    "plt.figsize=(20, 10)\n",
    "# Plot the bar graph\n",
    "plt.bar(indices, best_vector, label='Best')\n",
    "plt.bar(indices, worst_vector, label='Worst')\n",
    "plt.legend()\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Block Index')\n",
    "plt.ylabel('Block Selection Count')\n",
    "plt.xticks(list(range(0,12)))\n",
    "plt.yticks(list(range(0, max(best_vector)+1)))\n",
    "plt.title('Comparing the attention block selection frequency for best and worst performing vectors.')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Selection_Comparison_{}.png\".format(dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'CIFAR10'\n",
    "base_path = '/home/co-dutt1/rds/hpc-work/Layer-Masking/'\n",
    "csv = base_path + 'vit_base/' + dataset + '/tune_attention_blocks_random_vit_base_0.0001.csv'\n",
    "\n",
    "df = pd.read_csv(csv)\n",
    "#df['Vector Path'] = df['Vector Path'].apply(lambda x: os.path.join(base_path, x.split('/')[-1]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc = df['Test Acc@1'].mean()\n",
    "std_acc = df['Test Acc@1'].std()\n",
    "max_acc = df['Test Acc@1'].max()\n",
    "min_acc = df['Test Acc@1'].min()\n",
    "avg_train_percent = df['Train Percent'].mean()\n",
    "best_train_percent = df[df['Test Acc@1'] == max_acc]['Train Percent'].values[0]\n",
    "diff = max_acc - min_acc\n",
    "\n",
    "print(\"Mean Acc: \", mean_acc)\n",
    "print(\"Std Acc: \", std_acc)\n",
    "print(\"Max Acc: \", max_acc)\n",
    "print(\"Min Acc: \", min_acc)\n",
    "print(\"Avg Train Percent: \", avg_train_percent)\n",
    "print(\"Best train percent: \", best_train_percent)\n",
    "print(\"Difference (Max, Min): \", diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "best_df = df.sort_values(by=['Test Acc@1'], ascending=False).head(k).reset_index(drop=True)\n",
    "worst_df = df.sort_values(by=['Test Acc@1'], ascending=True).head(k).reset_index(drop=True)\n",
    "\n",
    "print(len(best_df), len(worst_df))\n",
    "worst_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_vector = np.array([0]*12)\n",
    "\n",
    "for i in range(len(best_df)):\n",
    "    vector_path = best_df['Vector Path'][i]\n",
    "    vector = np.load(vector_path)\n",
    "    best_vector += vector\n",
    "\n",
    "worst_vector = np.array([0]*12)\n",
    "\n",
    "for i in range(len(worst_df)):\n",
    "    vector_path = worst_df['Vector Path'][i]\n",
    "    vector = np.load(vector_path)\n",
    "    worst_vector += vector\n",
    "\n",
    "best_vector, worst_vector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many times was each block selected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See which blocks were activated the maximum number of times\n",
    "\n",
    "sum_vec = np.array([0]*12)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    vec = np.load(df['Vector Path'][i])\n",
    "    sum_vec += vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(sum_vec))\n",
    "\n",
    "plt.figsize=(20, 10)\n",
    "# Plot the bar graph\n",
    "plt.bar(indices, sum_vec)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Block Index')\n",
    "plt.ylabel('Number of Times Trainable')\n",
    "plt.xticks(list(range(0,12)))\n",
    "plt.yticks(list(range(0, max(sum_vec)+1)))\n",
    "plt.title('Bar Plot of the number of times each attention block was activated (in 50 runs) in a ViT-Base Model.')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Random_Attention_Block_Tuning_{}.png\".format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(best_vector))\n",
    "\n",
    "plt.figsize=(20, 10)\n",
    "# Plot the bar graph\n",
    "plt.bar(indices, best_vector, label='Best')\n",
    "plt.bar(indices, worst_vector, label='Worst')\n",
    "plt.legend()\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Block Index')\n",
    "plt.ylabel('Block Selection Count')\n",
    "plt.xticks(list(range(0,12)))\n",
    "plt.yticks(list(range(0, max(best_vector)+1)))\n",
    "plt.title('Comparing the attention block selection frequency for best and worst performing vectors.')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Selection_Comparison_{}.png\".format(dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retinopathy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'retinopathy'\n",
    "base_path = '/home/co-dutt1/rds/hpc-work/Layer-Masking/'\n",
    "csv = base_path + 'vit_base/' + dataset + '/tune_attention_blocks_random_vit_base_0.0001.csv'\n",
    "\n",
    "df = pd.read_csv(csv)\n",
    "#df['Vector Path'] = df['Vector Path'].apply(lambda x: os.path.join(base_path, x.split('/')[-1]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc = df['Test Acc@1'].mean()\n",
    "std_acc = df['Test Acc@1'].std()\n",
    "max_acc = df['Test Acc@1'].max()\n",
    "min_acc = df['Test Acc@1'].min()\n",
    "avg_train_percent = df['Train Percent'].mean()\n",
    "best_train_percent = df[df['Test Acc@1'] == max_acc]['Train Percent'].values[0]\n",
    "diff = max_acc - min_acc\n",
    "\n",
    "print(\"Mean Acc: \", mean_acc)\n",
    "print(\"Std Acc: \", std_acc)\n",
    "print(\"Max Acc: \", max_acc)\n",
    "print(\"Min Acc: \", min_acc)\n",
    "print(\"Avg Train Percent: \", avg_train_percent)\n",
    "print(\"Best Train Percent: \", best_train_percent)\n",
    "print(\"Difference (Max, Min): \", diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "best_df = df.sort_values(by=['Test Acc@1'], ascending=False).head(k).reset_index(drop=True)\n",
    "worst_df = df.sort_values(by=['Test Acc@1'], ascending=True).head(k).reset_index(drop=True)\n",
    "\n",
    "print(len(best_df), len(worst_df))\n",
    "worst_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_vector = np.array([0]*12)\n",
    "\n",
    "for i in range(len(best_df)):\n",
    "    vector_path = best_df['Vector Path'][i]\n",
    "    vector = np.load(vector_path)\n",
    "    best_vector += vector\n",
    "\n",
    "worst_vector = np.array([0]*12)\n",
    "\n",
    "for i in range(len(worst_df)):\n",
    "    vector_path = worst_df['Vector Path'][i]\n",
    "    vector = np.load(vector_path)\n",
    "    worst_vector += vector\n",
    "\n",
    "best_vector, worst_vector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many times was each block selected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See which blocks were activated the maximum number of times\n",
    "\n",
    "sum_vec = np.array([0]*12)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    vec = np.load(df['Vector Path'][i])\n",
    "    sum_vec += vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(sum_vec))\n",
    "\n",
    "plt.figsize=(20, 10)\n",
    "# Plot the bar graph\n",
    "plt.bar(indices, sum_vec)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Block Index')\n",
    "plt.ylabel('Number of Times Trainable')\n",
    "plt.xticks(list(range(0,12)))\n",
    "plt.yticks(list(range(0, max(sum_vec)+1)))\n",
    "plt.title('Bar Plot of the number of times each attention block was activated (in 50 runs) in a ViT-Base Model.')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Random_Attention_Block_Tuning_{}.png\".format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(best_vector))\n",
    "\n",
    "plt.figsize=(20, 10)\n",
    "# Plot the bar graph\n",
    "plt.bar(indices, best_vector, label='Best')\n",
    "plt.bar(indices, worst_vector, label='Worst')\n",
    "plt.legend()\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Block Index')\n",
    "plt.ylabel('Block Selection Count')\n",
    "plt.xticks(list(range(0,12)))\n",
    "plt.yticks(list(range(0, max(best_vector)+1)))\n",
    "plt.title('Comparing the attention block selection frequency for best and worst performing vectors.')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Selection_Comparison_{}.png\".format(dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pneumonia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_row_to_first(df):\n",
    "    last_row = df.iloc[-1]\n",
    "    df = pd.concat([last_row.to_frame().T, df], ignore_index=True)\n",
    "    df = df.drop(df.index[-1]).reset_index(drop=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_best_row(df):\n",
    "    best_row = df.sort_values(by=['Test Acc@1'], ascending=False).head(1).reset_index(drop=True)\n",
    "    return best_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6776/3061907849.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_breastUS = df_breastUS.append(best_row, ignore_index=True)\n",
      "/tmp/ipykernel_6776/3061907849.py:22: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_fitzpatrick = df_fitzpatrick.append(best_row, ignore_index=True)\n",
      "/tmp/ipykernel_6776/3061907849.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_ham10k = df_ham10k.append(best_row, ignore_index=True)\n",
      "/tmp/ipykernel_6776/3061907849.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_smdg = df_smdg.append(best_row, ignore_index=True)\n",
      "/tmp/ipykernel_6776/3061907849.py:49: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_retinopathy = df_retinopathy.append(best_row, ignore_index=True)\n",
      "/tmp/ipykernel_6776/3061907849.py:58: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_CIFAR10 = df_CIFAR10.append(best_row, ignore_index=True)\n",
      "/tmp/ipykernel_6776/3061907849.py:67: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_CIFAR100 = df_CIFAR100.append(best_row, ignore_index=True)\n",
      "/tmp/ipykernel_6776/3061907849.py:76: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df_pneumonia = df_pneumonia.append(best_row, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "base_path = '/home/co-dutt1/rds/hpc-work/Layer-Masking/'\n",
    "\n",
    "csv_name = 'Fixed_Vectors_tune_attention_blocks_random_vit_base_0.0001.csv'\n",
    "csv_name2 = 'Fixed_Vectors_tune_attention_vit_base.csv'\n",
    "model = 'vit_base'\n",
    "\n",
    "dataset = 'breastUS'\n",
    "csv = os.path.join(base_path, model, dataset, csv_name)\n",
    "csv2 = os.path.join(base_path, model, dataset, csv_name2)\n",
    "df_breastUS = pd.read_csv(csv)\n",
    "df2 = pd.read_csv(csv2)\n",
    "best_row = get_best_row(df2)\n",
    "df_breastUS = df_breastUS.append(best_row, ignore_index=True)\n",
    "df_breastUS = last_row_to_first(df_breastUS)\n",
    "\n",
    "dataset = 'fitzpatrick'\n",
    "csv = os.path.join(base_path, model, dataset, csv_name)\n",
    "csv2 = os.path.join(base_path, model, dataset, csv_name2)\n",
    "df_fitzpatrick = pd.read_csv(csv)\n",
    "df2 = pd.read_csv(csv2)\n",
    "best_row = get_best_row(df2)\n",
    "df_fitzpatrick = df_fitzpatrick.append(best_row, ignore_index=True)\n",
    "df_fitzpatrick = last_row_to_first(df_fitzpatrick)\n",
    "\n",
    "dataset = 'HAM10000'\n",
    "csv = os.path.join(base_path, model, dataset, csv_name)\n",
    "csv2 = os.path.join(base_path, model, dataset, csv_name2)\n",
    "df_ham10k = pd.read_csv(csv)\n",
    "df2 = pd.read_csv(csv2)\n",
    "best_row = get_best_row(df2)\n",
    "df_ham10k = df_ham10k.append(best_row, ignore_index=True)\n",
    "df_ham10k = last_row_to_first(df_ham10k)\n",
    "\n",
    "dataset = 'smdg'\n",
    "csv = os.path.join(base_path, model, dataset, csv_name)\n",
    "csv2 = os.path.join(base_path, model, dataset, csv_name2)\n",
    "df_smdg = pd.read_csv(csv)\n",
    "df2 = pd.read_csv(csv2)\n",
    "best_row = get_best_row(df2)\n",
    "df_smdg = df_smdg.append(best_row, ignore_index=True)\n",
    "df_smdg = last_row_to_first(df_smdg)\n",
    "\n",
    "dataset = 'retinopathy'\n",
    "csv = os.path.join(base_path, model, dataset, csv_name)\n",
    "csv2 = os.path.join(base_path, model, dataset, csv_name2)\n",
    "df_retinopathy = pd.read_csv(csv)\n",
    "df2 = pd.read_csv(csv2)\n",
    "best_row = get_best_row(df2)\n",
    "df_retinopathy = df_retinopathy.append(best_row, ignore_index=True)\n",
    "df_retinopathy = last_row_to_first(df_retinopathy)\n",
    "\n",
    "dataset = 'CIFAR10'\n",
    "csv = os.path.join(base_path, model, dataset, csv_name)\n",
    "csv2 = os.path.join(base_path, model, dataset, csv_name2)\n",
    "df_CIFAR10 = pd.read_csv(csv)\n",
    "df2 = pd.read_csv(csv2)\n",
    "best_row = get_best_row(df2)\n",
    "df_CIFAR10 = df_CIFAR10.append(best_row, ignore_index=True)\n",
    "df_CIFAR10 = last_row_to_first(df_CIFAR10)\n",
    "\n",
    "dataset = 'CIFAR100'\n",
    "csv = os.path.join(base_path, model, dataset, csv_name)\n",
    "csv2 = os.path.join(base_path, model, dataset, csv_name2)\n",
    "df_CIFAR100 = pd.read_csv(csv)\n",
    "df2 = pd.read_csv(csv2)\n",
    "best_row = get_best_row(df2)\n",
    "df_CIFAR100 = df_CIFAR100.append(best_row, ignore_index=True)\n",
    "df_CIFAR100 = last_row_to_first(df_CIFAR100)\n",
    "\n",
    "dataset = 'pneumonia'\n",
    "csv = os.path.join(base_path, model, dataset, csv_name)\n",
    "csv2 = os.path.join(base_path, model, dataset, csv_name2)\n",
    "df_pneumonia = pd.read_csv(csv)\n",
    "df2 = pd.read_csv(csv2)\n",
    "best_row = get_best_row(df2)\n",
    "df_pneumonia = df_pneumonia.append(best_row, ignore_index=True)\n",
    "df_pneumonia = last_row_to_first(df_pneumonia)\n",
    "\n",
    "df_pneumonia.head()\n",
    "\n",
    "dataset_dict = {'breastUS': df_breastUS, 'fitzpatrick': df_fitzpatrick, 'HAM10000': df_ham10k, 'smdg': df_smdg, 'retinopathy': df_retinopathy, 'CIFAR10': df_CIFAR10, 'CIFAR100': df_CIFAR100, 'pneumonia': df_pneumonia}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76, 76, 76, 76, 76, 76, 76, 76)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_breastUS), len(df_fitzpatrick), len(df_ham10k), len(df_retinopathy), len(df_CIFAR10), len(df_CIFAR100), len(df_pneumonia), len(df_smdg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does selective attention fine-tuning compare to full-attention fine-tuning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  breastUS\n",
      "Best Performing Method:  tune_attention_blocks_random\n",
      "Best Test Acc:  94.80518846387989\n",
      "Full Attention FT:  89.51077922077921\n",
      "Difference:  5.294409243100674\n",
      "\n",
      "\n",
      "Dataset:  fitzpatrick\n",
      "Best Performing Method:  tune_attention_blocks_random\n",
      "Best Test Acc:  84.94690818238601\n",
      "Full Attention FT:  80.82299812617114\n",
      "Difference:  4.123910056214868\n",
      "\n",
      "\n",
      "Dataset:  HAM10000\n",
      "Best Performing Method:  tune_attention_blocks_random\n",
      "Best Test Acc:  91.70829170829172\n",
      "Full Attention FT:  90.4095904095904\n",
      "Difference:  1.2987012987013316\n",
      "\n",
      "\n",
      "Dataset:  smdg\n",
      "Best Performing Method:  tune_attention_blocks_random\n",
      "Best Test Acc:  90.0974025974026\n",
      "Full Attention FT:  89.12337662337663\n",
      "Difference:  0.9740259740259773\n",
      "\n",
      "\n",
      "Dataset:  retinopathy\n",
      "Best Performing Method:  tune_attention_blocks_random\n",
      "Best Test Acc:  77.39179954441913\n",
      "Full Attention FT:  72.89293849658314\n",
      "Difference:  4.498861047835987\n",
      "\n",
      "\n",
      "Dataset:  CIFAR10\n",
      "Best Performing Method:  tune_attention_blocks_random\n",
      "Best Test Acc:  99.03\n",
      "Full Attention FT:  98.89\n",
      "Difference:  0.14000000000000057\n",
      "\n",
      "\n",
      "Dataset:  CIFAR100\n",
      "Best Performing Method:  tune_attention_blocks_random\n",
      "Best Test Acc:  92.94\n",
      "Full Attention FT:  92.46\n",
      "Difference:  0.480000000000004\n",
      "\n",
      "\n",
      "Dataset:  pneumonia\n",
      "Best Performing Method:  tune_attention_blocks_random\n",
      "Best Test Acc:  85.76465403261349\n",
      "Full Attention FT:  85.36800352578229\n",
      "Difference:  0.3966505068312074\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_performance = []\n",
    "full_attention = []\n",
    "\n",
    "for dataset in dataset_dict.keys():\n",
    "    df = dataset_dict[dataset]\n",
    "    print(\"Dataset: \", dataset)\n",
    "    print(\"Best Performing Method: \", df[df['Test Acc@1'] == df['Test Acc@1'].max()]['Tuning Method'].values[0])\n",
    "    print(\"Best Test Acc: \", df['Test Acc@1'].max())\n",
    "    print(\"Full Attention FT: \", df[df['Tuning Method'] == 'tune_attention']['Test Acc@1'].values[0])\n",
    "    print(\"Difference: \", df['Test Acc@1'].max() - df[df['Tuning Method'] == 'tune_attention']['Test Acc@1'].values[0])\n",
    "    print(\"\\n\")\n",
    "    best_performance.append(df['Test Acc@1'].max())\n",
    "    full_attention.append(df[df['Tuning Method'] == 'tune_attention']['Test Acc@1'].values[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set the width of the bars\n",
    "bar_width = 0.35\n",
    "\n",
    "# Calculate the x-axis positions for the bars\n",
    "x = np.arange(len(dataset_dict.keys()))\n",
    "y = np.arange(0, 101, 5)\n",
    "\n",
    "# Create the figure and axis objects\n",
    "fig, ax = plt.subplots(figsize=(10, 12))\n",
    "\n",
    "# Difference between the two bars\n",
    "diff = np.array(best_performance) - np.array(full_attention)\n",
    "\n",
    "# Plot the bars\n",
    "ax.bar(x - bar_width/2, best_performance, width=bar_width, label='Selective Attention')\n",
    "ax.bar(x + bar_width/2, full_attention, width=bar_width, label='Full Attention')\n",
    "\n",
    "# Set the x-axis tick positions and labels\n",
    "ax.set_xticks(x)\n",
    "ax.set_yticks(y)\n",
    "ax.set_xticklabels(list(dataset_dict.keys()))\n",
    "ax.set_yticklabels(list(range(0, 101, 5)))\n",
    "ax.set_xlabel('Dataset')\n",
    "ax.set_ylabel('Test Accuracy')\n",
    "\n",
    "# Set the legend\n",
    "ax.legend()\n",
    "\n",
    "# Display the plot\n",
    "#plt.show()\n",
    "\n",
    "plt.savefig('../plots/selective_vs_full_attention.png')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Block Selection b/w best and worst performing vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort all the dataframes\n",
    "\n",
    "k = 10\n",
    "\n",
    "all_datasets = [df_breastUS, df_fitzpatrick, df_smdg, df_ham10k, df_retinopathy, df_CIFAR10, df_CIFAR100, df_pneumonia]\n",
    "_best = np.array([0]*12)\n",
    "_worst = np.array([0]*12)\n",
    "\n",
    "for df in all_datasets:\n",
    "    best_vector, worst_vector = create_best_worst_vectors(df)\n",
    "    _best += best_vector\n",
    "    _worst += worst_vector\n",
    "\n",
    "_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set the width of the bars\n",
    "bar_width = 0.35\n",
    "\n",
    "# Calculate the x-axis positions for the bars\n",
    "x = np.arange(len(_best))\n",
    "\n",
    "# Create the figure and axis objects\n",
    "fig, ax = plt.subplots(figsize=(10, 12))\n",
    "\n",
    "# Plot the bars\n",
    "ax.bar(x - bar_width/2, _best, width=bar_width, label='Best')\n",
    "ax.bar(x + bar_width/2, _worst, width=bar_width, label='Worst')\n",
    "\n",
    "# Set the x-axis tick positions and labels\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(list(range(0,12)))\n",
    "ax.set_xlabel('Block Index')\n",
    "ax.set_ylabel('Block Selection Count')\n",
    "\n",
    "# Set the legend\n",
    "ax.legend()\n",
    "\n",
    "# Display the plot\n",
    "#plt.show()\n",
    "\n",
    "plt.savefig('../plots/best_worst_blocks_selection_supervised_vitB.png')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking the vectors for each dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do we have common vectors for best (and worst) performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "\n",
    "best_df_breastUS = df_breastUS.sort_values(by=['Test Acc@1'], ascending=False).head(k).reset_index(drop=True)\n",
    "worst_df_breastUS = df_breastUS.sort_values(by=['Test Acc@1'], ascending=True).head(k).reset_index(drop=True)\n",
    "best_df_breastUS['Vector Index'] =  best_df_breastUS['Vector Path'].apply(lambda x: x.split('/')[-1].split('_')[-1].strip('.npy')).astype(int).astype(int)\n",
    "worst_df_breastUS['Vector Index'] =  worst_df_breastUS['Vector Path'].apply(lambda x: x.split('/')[-1].split('_')[-1].strip('.npy')).astype(int).astype(int)\n",
    "\n",
    "best_df_fitzpatrick = df_fitzpatrick.sort_values(by=['Test Acc@1'], ascending=False).head(k).reset_index(drop=True)\n",
    "worst_df_fitzpatrick = df_fitzpatrick.sort_values(by=['Test Acc@1'], ascending=True).head(k).reset_index(drop=True)\n",
    "best_df_fitzpatrick['Vector Index'] =  best_df_fitzpatrick['Vector Path'].apply(lambda x: x.split('/')[-1].split('_')[-1].strip('.npy')).astype(int)\n",
    "worst_df_fitzpatrick['Vector Index'] =  worst_df_fitzpatrick['Vector Path'].apply(lambda x: x.split('/')[-1].split('_')[-1].strip('.npy')).astype(int)\n",
    "\n",
    "best_df_ham10k = df_ham10k.sort_values(by=['Test Acc@1'], ascending=False).head(k).reset_index(drop=True)\n",
    "worst_df_ham10k = df_ham10k.sort_values(by=['Test Acc@1'], ascending=True).head(k).reset_index(drop=True)\n",
    "best_df_ham10k['Vector Index'] =  best_df_ham10k['Vector Path'].apply(lambda x: x.split('/')[-1].split('_')[-1].strip('.npy')).astype(int)\n",
    "worst_df_ham10k['Vector Index'] =  worst_df_ham10k['Vector Path'].apply(lambda x: x.split('/')[-1].split('_')[-1].strip('.npy')).astype(int)\n",
    "\n",
    "best_df_retinopathy = df_retinopathy.sort_values(by=['Test Acc@1'], ascending=False).head(k).reset_index(drop=True)\n",
    "worst_df_retinopathy = df_retinopathy.sort_values(by=['Test Acc@1'], ascending=True).head(k).reset_index(drop=True)\n",
    "best_df_retinopathy['Vector Index'] =  best_df_retinopathy['Vector Path'].apply(lambda x: x.split('/')[-1].split('_')[-1].strip('.npy')).astype(int)\n",
    "worst_df_retinopathy['Vector Index'] =  worst_df_retinopathy['Vector Path'].apply(lambda x: x.split('/')[-1].split('_')[-1].strip('.npy')).astype(int)\n",
    "\n",
    "best_df_CIFAR10 = df_CIFAR10.sort_values(by=['Test Acc@1'], ascending=False).head(k).reset_index(drop=True)\n",
    "worst_df_CIFAR10 = df_CIFAR10.sort_values(by=['Test Acc@1'], ascending=True).head(k).reset_index(drop=True)\n",
    "best_df_CIFAR10['Vector Index'] =  best_df_CIFAR10['Vector Path'].apply(lambda x: x.split('/')[-1].split('_')[-1].strip('.npy')).astype(int)\n",
    "worst_df_CIFAR10['Vector Index'] =  worst_df_CIFAR10['Vector Path'].apply(lambda x: x.split('/')[-1].split('_')[-1].strip('.npy')).astype(int)\n",
    "\n",
    "best_df_CIFAR100 = df_CIFAR100.sort_values(by=['Test Acc@1'], ascending=False).head(k).reset_index(drop=True)\n",
    "worst_df_CIFAR100 = df_CIFAR100.sort_values(by=['Test Acc@1'], ascending=True).head(k).reset_index(drop=True)\n",
    "best_df_CIFAR100['Vector Index'] =  best_df_CIFAR100['Vector Path'].apply(lambda x: x.split('/')[-1].split('_')[-1].strip('.npy')).astype(int)\n",
    "worst_df_CIFAR100['Vector Index'] =  worst_df_CIFAR100['Vector Path'].apply(lambda x: x.split('/')[-1].split('_')[-1].strip('.npy')).astype(int)\n",
    "\n",
    "best_df_pneumonia = df_pneumonia.sort_values(by=['Test Acc@1'], ascending=False).head(k).reset_index(drop=True)\n",
    "worst_df_pneumonia = df_pneumonia.sort_values(by=['Test Acc@1'], ascending=True).head(k).reset_index(drop=True)\n",
    "best_df_pneumonia['Vector Index'] =  best_df_pneumonia['Vector Path'].apply(lambda x: x.split('/')[-1].split('_')[-1].strip('.npy')).astype(int)\n",
    "worst_df_pneumonia['Vector Index'] =  worst_df_pneumonia['Vector Path'].apply(lambda x: x.split('/')[-1].split('_')[-1].strip('.npy')).astype(int)\n",
    "\n",
    "best_df_smdg = df_smdg.sort_values(by=['Test Acc@1'], ascending=False).head(k).reset_index(drop=True)\n",
    "worst_df_smdg = df_smdg.sort_values(by=['Test Acc@1'], ascending=True).head(k).reset_index(drop=True)\n",
    "best_df_smdg['Vector Index'] =  best_df_smdg['Vector Path'].apply(lambda x: x.split('/')[-1].split('_')[-1].strip('.npy')).astype(int)\n",
    "worst_df_smdg['Vector Index'] =  worst_df_smdg['Vector Path'].apply(lambda x: x.split('/')[-1].split('_')[-1].strip('.npy')).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_breastUS_best = set(best_df_breastUS['Vector Index'])\n",
    "set_fitzpatrick_best = set(best_df_fitzpatrick['Vector Index'])\n",
    "set_ham10k_best = set(best_df_ham10k['Vector Index'])\n",
    "set_retinopathy_best = set(best_df_retinopathy['Vector Index'])\n",
    "set_CIFAR10_best = set(best_df_CIFAR10['Vector Index'])\n",
    "set_CIFAR100_best = set(best_df_CIFAR100['Vector Index'])\n",
    "set_pneumonia_best = set(best_df_pneumonia['Vector Index'])\n",
    "set_smdg_best = set(best_df_smdg['Vector Index'])\n",
    "\n",
    "set_breastUS_worst = set(worst_df_breastUS['Vector Index'])\n",
    "set_fitzpatrick_worst = set(worst_df_fitzpatrick['Vector Index'])\n",
    "set_ham10k_worst = set(worst_df_ham10k['Vector Index'])\n",
    "set_retinopathy_worst = set(worst_df_retinopathy['Vector Index'])\n",
    "set_CIFAR10_worst = set(worst_df_CIFAR10['Vector Index'])\n",
    "set_CIFAR100_worst = set(worst_df_CIFAR100['Vector Index'])\n",
    "set_pneumonia_worst = set(worst_df_pneumonia['Vector Index'])\n",
    "set_smdg_worst = set(worst_df_smdg['Vector Index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is any overlap between the best and worst vectors\n",
    "\n",
    "common_best_vector = set.intersection(set_breastUS_best, set_fitzpatrick_best, set_ham10k_best, set_retinopathy_best, set_CIFAR10_best, set_CIFAR100_best, set_pneumonia_best, set_smdg_best)\n",
    "print(\"Common Best Vector: \", common_best_vector)  \n",
    "\n",
    "common_worst_vector = set.intersection(set_breastUS_worst, set_fitzpatrick_worst, set_ham10k_worst, set_retinopathy_worst, set_CIFAR10_worst, set_CIFAR100_worst, set_pneumonia_worst, set_smdg_worst)\n",
    "print(\"Common Worst Vector: \", common_worst_vector)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: There is no common vector between the best and worst vectors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How sensitive is the final performance to the block activation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in dataset_dict:\n",
    "    df = dataset_dict[dataset]\n",
    "    max_acc = df['Test Acc@1'].max()\n",
    "    min_acc = df['Test Acc@1'].min()\n",
    "    mean = df['Test Acc@1'].mean()\n",
    "    std = df['Test Acc@1'].std()\n",
    "    difference = max_acc - min_acc\n",
    "\n",
    "    print(\"Max Acc {}: {}\".format(dataset, max_acc))\n",
    "    print(\"Min Acc {}: {}\".format(dataset, min_acc))\n",
    "    print(\"Difference {}: {}\".format(dataset, difference))\n",
    "    print(\"Mean {}: {}\".format(dataset, mean))\n",
    "    print(\"Std {}: {}\".format(dataset, std))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do the vectors of best and worst performance look like for each dataset?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  breastUS\n",
      "Best Vector:  [0 1 0 1 1 0 1 1 0 0 1 1]\n",
      "Worst Vector:  [0 0 1 0 1 1 0 0 0 1 0 0]\n",
      "Cosine Similarity:  0.18898223650461365\n",
      "Hamming Distance:  0.75\n",
      "Performance Difference:  15.584409243100666\n",
      "\n",
      "\n",
      "Dataset:  fitzpatrick\n",
      "Best Vector:  [0 1 1 0 1 1 0 1 1 0 1 1]\n",
      "Worst Vector:  [1 1 1 0 1 0 1 1 1 1 1 0]\n",
      "Cosine Similarity:  0.7071067811865475\n",
      "Hamming Distance:  0.4166666666666667\n",
      "Performance Difference:  14.553404122423487\n",
      "\n",
      "\n",
      "Dataset:  HAM10000\n",
      "Best Vector:  [1 1 0 0 1 0 1 1 0 1 1 1]\n",
      "Worst Vector:  [0 1 0 0 0 1 0 0 0 0 0 0]\n",
      "Cosine Similarity:  0.25\n",
      "Hamming Distance:  0.6666666666666666\n",
      "Performance Difference:  5.994005994006017\n",
      "\n",
      "\n",
      "Dataset:  smdg\n",
      "Best Vector:  [1 0 0 1 1 1 1 1 1 0 0 0]\n",
      "Worst Vector:  [1 0 0 0 1 1 0 1 1 0 0 1]\n",
      "Cosine Similarity:  0.7715167498104595\n",
      "Hamming Distance:  0.25\n",
      "Performance Difference:  6.57467532467534\n",
      "\n",
      "\n",
      "Dataset:  retinopathy\n",
      "Best Vector:  [0 0 1 1 1 0 0 1 0 0 1 0]\n",
      "Worst Vector:  [1 1 1 0 1 0 1 1 1 1 1 0]\n",
      "Cosine Similarity:  0.5962847939999438\n",
      "Hamming Distance:  0.5\n",
      "Performance Difference:  42.82460136674259\n",
      "\n",
      "\n",
      "Dataset:  CIFAR10\n",
      "Best Vector:  [1 1 0 1 0 1 0 0 1 1 1 1]\n",
      "Worst Vector:  [0 0 0 1 0 1 0 1 0 0 0 0]\n",
      "Cosine Similarity:  0.408248290463863\n",
      "Hamming Distance:  0.5833333333333334\n",
      "Performance Difference:  0.9500000000000028\n",
      "\n",
      "\n",
      "Dataset:  CIFAR100\n",
      "Best Vector:  [0 1 1 0 1 1 0 1 1 0 1 1]\n",
      "Worst Vector:  [0 1 1 0 0 1 0 0 0 0 0 0]\n",
      "Cosine Similarity:  0.6123724356957945\n",
      "Hamming Distance:  0.4166666666666667\n",
      "Performance Difference:  18.060000000000002\n",
      "\n",
      "\n",
      "Dataset:  pneumonia\n",
      "Best Vector:  [1 1 1 1 0 0 1 0 0 0 0 0]\n",
      "Worst Vector:  [0 0 1 0 0 1 1 1 0 1 0 1]\n",
      "Cosine Similarity:  0.3651483716701107\n",
      "Hamming Distance:  0.5833333333333334\n",
      "Performance Difference:  4.671661524900841\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for dataset in dataset_dict:\n",
    "    df = dataset_dict[dataset]\n",
    "    max_acc = df['Test Acc@1'].max()\n",
    "    min_acc = df['Test Acc@1'].min()\n",
    "\n",
    "    best_vector = np.load(df[df['Test Acc@1'] == max_acc]['Vector Path'].values[0])\n",
    "    worst_vector = np.load(df[df['Test Acc@1'] == min_acc]['Vector Path'].values[0])\n",
    "    cos_dist = distance.cosine(best_vector, worst_vector)\n",
    "    cos_similarity = 1 - cos_dist\n",
    "    hamming_dist = distance.hamming(best_vector, worst_vector)\n",
    "\n",
    "    print(\"Dataset: \", dataset)\n",
    "    print(\"Best Vector: \", best_vector)\n",
    "    print(\"Worst Vector: \", worst_vector)\n",
    "    print(\"Cosine Similarity: \", cos_similarity)\n",
    "    print(\"Hamming Distance: \", hamming_dist)\n",
    "    print(\"Performance Difference: \", max_acc - min_acc)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Cosine Similarity b/w Best and Worst vectors respectively for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_acc_breastUS = df_breastUS['Test Acc@1'].max()\n",
    "min_acc_breastUS = df_breastUS['Test Acc@1'].min()\n",
    "\n",
    "max_acc_fitzpatrick = df_fitzpatrick['Test Acc@1'].max()\n",
    "min_acc_fitzpatrick = df_fitzpatrick['Test Acc@1'].min()\n",
    "\n",
    "max_acc_ham10k = df_ham10k['Test Acc@1'].max()\n",
    "min_acc_ham10k = df_ham10k['Test Acc@1'].min()\n",
    "\n",
    "max_acc_retinopathy = df_retinopathy['Test Acc@1'].max()\n",
    "min_acc_retinopathy = df_retinopathy['Test Acc@1'].min()\n",
    "\n",
    "max_acc_CIFAR10 = df_CIFAR10['Test Acc@1'].max()\n",
    "min_acc_CIFAR10 = df_CIFAR10['Test Acc@1'].min()\n",
    "\n",
    "max_acc_CIFAR100 = df_CIFAR100['Test Acc@1'].max()\n",
    "min_acc_CIFAR100 = df_CIFAR100['Test Acc@1'].min()\n",
    "\n",
    "max_acc_pneumonia = df_pneumonia['Test Acc@1'].max()\n",
    "min_acc_pneumonia = df_pneumonia['Test Acc@1'].min()\n",
    "\n",
    "max_acc_smdg = df_smdg['Test Acc@1'].max()\n",
    "min_acc_smdg = df_smdg['Test Acc@1'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_vector_breastUS = np.load(df_breastUS[df_breastUS['Test Acc@1'] == max_acc_breastUS]['Vector Path'].values[0])\n",
    "best_vector_fitzpatrick = np.load(df_fitzpatrick[df_fitzpatrick['Test Acc@1'] == max_acc_fitzpatrick]['Vector Path'].values[0])\n",
    "best_vector_ham10k = np.load(df_ham10k[df_ham10k['Test Acc@1'] == max_acc_ham10k]['Vector Path'].values[0])\n",
    "best_vector_smdg = np.load(df_smdg[df_smdg['Test Acc@1'] == max_acc_smdg]['Vector Path'].values[0])\n",
    "best_vector_retinopathy = np.load(df_retinopathy[df_retinopathy['Test Acc@1'] == max_acc_retinopathy]['Vector Path'].values[0])\n",
    "best_vector_CIFAR10 = np.load(df_CIFAR10[df_CIFAR10['Test Acc@1'] == max_acc_CIFAR10]['Vector Path'].values[0])\n",
    "best_vector_CIFAR100 = np.load(df_CIFAR100[df_CIFAR100['Test Acc@1'] == max_acc_CIFAR100]['Vector Path'].values[0])\n",
    "best_vector_pneumonia = np.load(df_pneumonia[df_pneumonia['Test Acc@1'] == max_acc_pneumonia]['Vector Path'].values[0])\n",
    "\n",
    "worst_vector_breastUS = np.load(df_breastUS[df_breastUS['Test Acc@1'] == min_acc_breastUS]['Vector Path'].values[0])\n",
    "worst_vector_fitzpatrick = np.load(df_fitzpatrick[df_fitzpatrick['Test Acc@1'] == min_acc_fitzpatrick]['Vector Path'].values[0])\n",
    "worst_vector_ham10k = np.load(df_ham10k[df_ham10k['Test Acc@1'] == min_acc_ham10k]['Vector Path'].values[0])\n",
    "worst_vector_smdg = np.load(df_smdg[df_smdg['Test Acc@1'] == min_acc_smdg]['Vector Path'].values[0])\n",
    "worst_vector_retinopathy = np.load(df_retinopathy[df_retinopathy['Test Acc@1'] == min_acc_retinopathy]['Vector Path'].values[0])\n",
    "worst_vector_CIFAR10 = np.load(df_CIFAR10[df_CIFAR10['Test Acc@1'] == min_acc_CIFAR10]['Vector Path'].values[0])\n",
    "worst_vector_CIFAR100 = np.load(df_CIFAR100[df_CIFAR100['Test Acc@1'] == min_acc_CIFAR100]['Vector Path'].values[0])\n",
    "worst_vector_pneumonia = np.load(df_pneumonia[df_pneumonia['Test Acc@1'] == min_acc_pneumonia]['Vector Path'].values[0])\n",
    "\n",
    "all_best_vectors = [best_vector_breastUS, best_vector_fitzpatrick, best_vector_ham10k, best_vector_smdg, best_vector_retinopathy, best_vector_CIFAR10, best_vector_CIFAR100, best_vector_pneumonia]\n",
    "all_worst_vectors = [worst_vector_breastUS, worst_vector_fitzpatrick, worst_vector_ham10k, worst_vector_smdg, worst_vector_retinopathy, worst_vector_CIFAR10, worst_vector_CIFAR100, worst_vector_pneumonia]\n",
    "\n",
    "best_vectors = []\n",
    "for vector in all_best_vectors:\n",
    "    best_vectors.append(vector)\n",
    "\n",
    "worst_vectors = []\n",
    "for vector in all_worst_vectors:\n",
    "    worst_vectors.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vectors = len(best_vectors)\n",
    "similarity_matrix = np.zeros((num_vectors, num_vectors))\n",
    "\n",
    "for i in range(num_vectors):\n",
    "    for j in range(num_vectors):\n",
    "        cos_dist = distance.cosine(best_vectors[i], best_vectors[j])\n",
    "        cos_similarity = 1 - cos_dist\n",
    "        similarity_matrix[i, j] = cos_similarity\n",
    "        #print(\"Cosine Sim b/w vector {} and {}: \".format(str(i), str(j)), cos_similarity)\n",
    "\n",
    "similarity_df_best = pd.DataFrame(similarity_matrix)\n",
    "\n",
    "similarity_matrix = np.zeros((num_vectors, num_vectors))\n",
    "for i in range(num_vectors):\n",
    "    for j in range(num_vectors):\n",
    "        cos_dist = distance.cosine(worst_vectors[i], worst_vectors[j])\n",
    "        cos_similarity = 1 - cos_dist\n",
    "        similarity_matrix[i, j] = cos_similarity\n",
    "        #print(\"Cosine Sim b/w vector {} and {}: \".format(str(i), str(j)), cos_similarity)\n",
    "\n",
    "similarity_df_worst = pd.DataFrame(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix using seaborn and save it as a figure\n",
    "tuning_method = 'tune_attention_blocks_random'\n",
    "top_k = 10\n",
    "datasets = ['BreastUS', 'Fitzpatrick', 'HAM10000', 'SMDG', 'Retinopathy', 'CIFAR10', 'CIFAR100', 'Pneumonia']\n",
    "pos = [0.5,1.5,2.5,3.5,4.5,5.5,6.5,7.5]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "sns.heatmap(similarity_df_best, annot=True, fmt='.2f', cmap='coolwarm')\n",
    "plt.xlabel(\"Datasets\")\n",
    "plt.ylabel(\"Datasets\")\n",
    "plt.xticks(pos, datasets)\n",
    "plt.yticks(pos, datasets)\n",
    "plt.title(\"Cos-Sim b/w best performing vectors\")\n",
    "plt.savefig('../plots/best_cosine_sim_{}.png'.format(tuning_method))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix using seaborn and save it as a figure\n",
    "tuning_method = 'tune_attention_blocks_random'\n",
    "top_k = 10\n",
    "datasets = ['BreastUS', 'Fitzpatrick', 'HAM10000', 'SMDG', 'Retinopathy', 'CIFAR10', 'CIFAR100', 'Pneumonia']\n",
    "pos = [0.5,1.5,2.5,3.5,4.5,5.5,6.5,7.5]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "sns.heatmap(similarity_df_worst, annot=True, fmt='.2f', cmap='coolwarm')\n",
    "plt.xlabel(\"Vectors\")\n",
    "plt.ylabel(\"Vectors\")\n",
    "plt.xticks(pos, datasets)\n",
    "plt.yticks(pos, datasets)\n",
    "plt.title(\"Cos-Sim b/w worst performing vectors\")\n",
    "plt.savefig('../plots/worst_cosine_sim_{}.png'.format(tuning_method))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking each vector for all the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/co-dutt1/rds/hpc-work/Layer-Masking/'\n",
    "\n",
    "csv_name = 'Fixed_Vectors_tune_attention_blocks_random_vit_base_0.0001.csv'\n",
    "csv_name2 = 'Fixed_Vectors_tune_attention_vit_base.csv'\n",
    "model = 'vit_base'\n",
    "\n",
    "dataset = 'breastUS'\n",
    "csv = os.path.join(base_path, model, dataset, csv_name)\n",
    "df_breastUS = pd.read_csv(csv)\n",
    "\n",
    "dataset = 'fitzpatrick'\n",
    "csv = os.path.join(base_path, model, dataset, csv_name)\n",
    "df_fitzpatrick = pd.read_csv(csv)\n",
    "\n",
    "dataset = 'HAM10000'\n",
    "csv = os.path.join(base_path, model, dataset, csv_name)\n",
    "df_ham10k = pd.read_csv(csv)\n",
    "\n",
    "dataset = 'smdg'\n",
    "csv = os.path.join(base_path, model, dataset, csv_name)\n",
    "df_smdg = pd.read_csv(csv)\n",
    "\n",
    "dataset = 'retinopathy'\n",
    "csv = os.path.join(base_path, model, dataset, csv_name)\n",
    "df_retinopathy = pd.read_csv(csv)\n",
    "\n",
    "dataset = 'CIFAR10'\n",
    "csv = os.path.join(base_path, model, dataset, csv_name)\n",
    "df_CIFAR10 = pd.read_csv(csv)\n",
    "\n",
    "dataset = 'CIFAR100'\n",
    "csv = os.path.join(base_path, model, dataset, csv_name)\n",
    "df_CIFAR100 = pd.read_csv(csv)\n",
    "\n",
    "dataset = 'pneumonia'\n",
    "csv = os.path.join(base_path, model, dataset, csv_name)\n",
    "df_pneumonia = pd.read_csv(csv)\n",
    "\n",
    "df_pneumonia.head()\n",
    "\n",
    "dataset_dict = {'breastUS': df_breastUS, 'fitzpatrick': df_fitzpatrick, 'HAM10000': df_ham10k, 'smdg': df_smdg, 'retinopathy': df_retinopathy, 'CIFAR10': df_CIFAR10, 'CIFAR100': df_CIFAR100, 'pneumonia': df_pneumonia}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.DataFrame()\n",
    "\n",
    "merged_df['Tuning Method'] = df_breastUS['Tuning Method']\n",
    "merged_df['Train Percent'] = df_breastUS['Train Percent']\n",
    "merged_df['Vector'] = df_breastUS['Vector Path'].apply(lambda x: x.split('/')[-1])\n",
    "merged_df['Combined Rank'] = 0\n",
    "\n",
    "\n",
    "for dataset in dataset_dict.keys():\n",
    "    df = dataset_dict[dataset]\n",
    "    rank_col = dataset + '_rank'\n",
    "    acc_col = dataset + '_acc'\n",
    "    merged_df[rank_col] = df['Test Acc@1'].rank(ascending=False)\n",
    "    #merged_df[acc_col] = df['Test Acc@1']\n",
    "\n",
    "for i in range(len(merged_df)):\n",
    "    merged_df['Combined Rank'][i] = merged_df.iloc[i, 3:11].sum()/8\n",
    "\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "merged_df_best = merged_df.sort_values(by=['Combined Rank'], ascending=True).head(k).reset_index(drop=True) #Smaller the rank the better\n",
    "merged_df_worst = merged_df.sort_values(by=['Combined Rank'], ascending=False).head(k).reset_index(drop=True)\n",
    "\n",
    "merged_df_best.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
