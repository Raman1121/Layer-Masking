{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from scipy.spatial import distance\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disable_module(module):\n",
    "    for p in module.parameters():\n",
    "        p.requires_grad = False\n",
    "        \n",
    "def enable_module(module):\n",
    "    for p in module.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "\n",
    "def check_tunable_params(model, verbose=True):\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            if(verbose):\n",
    "                print(name)\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.5f}\"\n",
    "    )\n",
    "\n",
    "    return trainable_params, all_param\n",
    "\n",
    "def create_mapping(model, vector):\n",
    "    mapping = {}\n",
    "    i = 0\n",
    "\n",
    "    for name_p,p in model.named_parameters():\n",
    "        if '.attn.' in name_p or 'attention' in name_p:\n",
    "            mapping[name_p] = vector[i]\n",
    "            i += 1\n",
    "        else:\n",
    "            p.requires_grad = False\n",
    "            \n",
    "    return mapping\n",
    "\n",
    "def sort_dict(dict, descending=False):\n",
    "    sorted_dict = dict(sorted(dict.items(), key=lambda item: item[1], reverse=descending))\n",
    "    \n",
    "    return sorted_dict\n",
    "\n",
    "def get_modules_from_vector(vector, model):\n",
    "    trainable_blocks = []\n",
    "    frozen_blocks = []\n",
    "    \n",
    "    trainable_blocks = np.where(np.array(vector) == 1)\n",
    "    frozen_blocks = np.where(np.array(vector) == 0)\n",
    "    \n",
    "    return trainable_blocks, frozen_blocks\n",
    "\n",
    "def get_model_for_bitfit(model):\n",
    "    trainable_components = ['bias', 'pooler.dense.bias', 'head'] \n",
    "\n",
    "    # Disale all the gradients\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False \n",
    "      \n",
    "    vector = []\n",
    "\n",
    "    for name, param in model.named_parameters():\n",
    "        for component in trainable_components:\n",
    "            if component in name:\n",
    "                vector.append(1)\n",
    "                param.requires_grad = True\n",
    "                break\n",
    "    \n",
    "    return vector\n",
    "\n",
    "def enable_from_vector(vector, model):\n",
    "    print(\"Vector: \", vector)\n",
    "    \n",
    "    disable_module(model)\n",
    "    \n",
    "    for idx, block in enumerate(model.blocks): \n",
    "    \n",
    "        if(vector[idx] == 1):\n",
    "            print(\"Enabling attention in Block {}\".format(idx))\n",
    "            enable_module(block.attn)\n",
    "        else:\n",
    "            #print(\"Disabling attention in Block {}\".format(idx))\n",
    "            disable_module(block.attn)\n",
    "\n",
    "def create_best_worst_vectors(df, k=10):\n",
    "    best_df = df.sort_values(by=['Test Acc@1'], ascending=False).head(k).reset_index(drop=True)\n",
    "    worst_df = df.sort_values(by=['Test Acc@1'], ascending=True).head(k).reset_index(drop=True)\n",
    "\n",
    "    best_vector = np.array([0]*12)\n",
    "\n",
    "    for i in range(len(best_df)):\n",
    "        vector_path = best_df['Vector Path'][i]\n",
    "        vector = np.load(vector_path)\n",
    "        best_vector += vector\n",
    "\n",
    "    worst_vector = np.array([0]*12)\n",
    "\n",
    "    for i in range(len(worst_df)):\n",
    "        vector_path = worst_df['Vector Path'][i]\n",
    "        vector = np.load(vector_path)\n",
    "        worst_vector += vector\n",
    "\n",
    "    return best_vector, worst_vector\n",
    "\n",
    "def tune_blocks_random(model, mask, segment):\n",
    "\n",
    "    vector = []\n",
    "\n",
    "    for idx, block in enumerate(model.blocks):\n",
    "\n",
    "        if(mask is None):\n",
    "            bit = int(np.random.random(1)[0] > 0.5)\n",
    "        else:\n",
    "            bit = mask[idx]\n",
    "\n",
    "        if(bit == 1):\n",
    "            print(\"Enabling {} in Block {}\".format(segment, idx))\n",
    "            if(segment == 'attention'):\n",
    "                enable_module(block.attn)\n",
    "            elif(segment == 'layernorm'):\n",
    "                enable_module(block.norm1)\n",
    "                enable_module(block.norm2)\n",
    "\n",
    "            vector.append(1)\n",
    "        else:\n",
    "            print(\"Disabling {} in Block {}\".format(segment, idx))\n",
    "            if(segment == 'attention'):\n",
    "                disable_module(block.attn)\n",
    "            elif(segment == 'layernorm'):\n",
    "                disable_module(block.norm1)\n",
    "                disable_module(block.norm2)\n",
    "            \n",
    "            vector.append(0)\n",
    "    \n",
    "    if(mask is not None):\n",
    "        assert (mask == vector)\n",
    "        \n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = timm.create_model('vit_base_patch16_224', pretrained=False)\n",
    "num_blocks = len(model.blocks)\n",
    "mask = list(np.random.randint(low=0, high=2, size=num_blocks))\n",
    "\n",
    "disable_module(model)\n",
    "\n",
    "\n",
    "vector = tune_blocks_random(model, mask, 'attention')\n",
    "print(\"Vector: \", vector)\n",
    "print(\"Mask: \", mask)\n",
    "\n",
    "check_tunable_params(model, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/co-dutt1/rds/hpc-work/Layer-Masking/Experiment_Vectors/\"\n",
    "\n",
    "for i in range(1, 51):\n",
    "    vector = np.random.randint(low=0, high=2, size=num_blocks)\n",
    "    np.save(path + \"random_vector_{}.npy\".format(i), vector)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Attention Tuning (Block Level)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BreastUS Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/co-dutt1/rds/hpc-work/Layer-Masking/'\n",
    "csv = base_path + 'vit_base/breastUS/' + 'tune_attention_blocks_random_vit_base_0.0001.csv'\n",
    "\n",
    "df = pd.read_csv(csv)\n",
    "#df['Vector Path'] = df['Vector Path'].apply(lambda x: os.path.join(base_path, x.split('/')[-1]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc = df['Test Acc@1'].mean()\n",
    "std_acc = df['Test Acc@1'].std()\n",
    "max_acc = df['Test Acc@1'].max()\n",
    "min_acc = df['Test Acc@1'].min()\n",
    "avg_train_percent = df['Train Percent'].mean()\n",
    "diff = max_acc - min_acc\n",
    "best_train_percent = df[df['Test Acc@1'] == max_acc]['Train Percent'].values[0]\n",
    "\n",
    "print(\"Mean Acc: \", mean_acc)\n",
    "print(\"Std Acc: \", std_acc)\n",
    "print(\"Max Acc: \", max_acc)\n",
    "print(\"Min Acc: \", min_acc)\n",
    "print(\"Avg Train Percent: \", avg_train_percent)\n",
    "print(\"Best Performance Train Percent: \", best_train_percent)\n",
    "print(\"Diff: \", diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower_threshold = df['Test Acc@1'].quantile(0.10)\n",
    "# upper_threshold = df['Test Acc@1'].quantile(0.90)\n",
    "\n",
    "# top_1_percent = df[df['Test Acc@1'] >= upper_threshold].reset_index(drop=True)\n",
    "# bottom_1_percent = df[df['Test Acc@1'] <= lower_threshold].reset_index(drop=True)\n",
    "\n",
    "# bottom_1_percent\n",
    "\n",
    "k = 10\n",
    "best_df = df.sort_values(by=['Test Acc@1'], ascending=False).head(k).reset_index(drop=True)\n",
    "worst_df = df.sort_values(by=['Test Acc@1'], ascending=True).head(k).reset_index(drop=True)\n",
    "\n",
    "print(len(best_df), len(worst_df))\n",
    "best_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_vector = np.array([0]*12)\n",
    "\n",
    "for i in range(len(best_df)):\n",
    "    vector_path = best_df['Vector Path'][i]\n",
    "    vector = np.load(vector_path)\n",
    "    best_vector += vector\n",
    "\n",
    "worst_vector = np.array([0]*12)\n",
    "\n",
    "for i in range(len(worst_df)):\n",
    "    vector_path = worst_df['Vector Path'][i]\n",
    "    vector = np.load(vector_path)\n",
    "    worst_vector += vector\n",
    "\n",
    "best_vector, worst_vector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many times was each block trained during 50 runs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See which blocks were activated the maximum number of times\n",
    "\n",
    "sum_vec = np.array([0]*12)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    vec = np.load(df['Vector Path'][i])\n",
    "    sum_vec += vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(sum_vec))\n",
    "\n",
    "plt.figsize=(20, 10)\n",
    "# Plot the bar graph\n",
    "plt.bar(indices, sum_vec)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Block Index')\n",
    "plt.ylabel('Number of Times Trainable')\n",
    "plt.xticks(list(range(0,12)))\n",
    "plt.yticks(list(range(0, max(sum_vec)+1)))\n",
    "plt.title('Bar Plot of the number of times each attention block was activated (in 50 runs) in a ViT-Base Model.')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Random_Attention_Block_Tuning_breastUS.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(best_vector))\n",
    "\n",
    "plt.figsize=(20, 10)\n",
    "# Plot the bar graph\n",
    "plt.bar(indices, best_vector, label='Best')\n",
    "plt.bar(indices, worst_vector, label='Worst')\n",
    "plt.legend()\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Block Index')\n",
    "plt.ylabel('Block Selection Count')\n",
    "plt.xticks(list(range(0,12)))\n",
    "plt.yticks(list(range(0, max(best_vector)+1)))\n",
    "plt.title('Comparing the attention block selection frequency for best and worst performing vectors.')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Selection_Comparison_BreastUS.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the best performing vectors tune later blocks more than the worst performing vectors."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FitzPatrick Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'fitzpatrick'\n",
    "base_path = '/home/co-dutt1/rds/hpc-work/Layer-Masking/'\n",
    "csv = base_path + 'vit_base/' + dataset + '/tune_attention_blocks_random_vit_base_0.0001.csv'\n",
    "\n",
    "df = pd.read_csv(csv)\n",
    "#df['Vector Path'] = df['Vector Path'].apply(lambda x: os.path.join(base_path, x.split('/')[-1]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc = df['Test Acc@1'].mean()\n",
    "std_acc = df['Test Acc@1'].std()\n",
    "max_acc = df['Test Acc@1'].max()\n",
    "min_acc = df['Test Acc@1'].min()\n",
    "avg_train_percent = df['Train Percent'].mean()\n",
    "best_train_percent = df[df['Test Acc@1'] == max_acc]['Train Percent'].values[0]\n",
    "diff = max_acc - min_acc\n",
    "\n",
    "print(\"Mean Acc: \", mean_acc)\n",
    "print(\"Std Acc: \", std_acc)\n",
    "print(\"Max Acc: \", max_acc)\n",
    "print(\"Min Acc: \", min_acc)\n",
    "print(\"Avg Train Percent: \", avg_train_percent)\n",
    "print(\"Best Performance Train Percent: \", best_train_percent)\n",
    "print(\"Difference (Max, Min): \", diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "best_df = df.sort_values(by=['Test Acc@1'], ascending=False).head(k).reset_index(drop=True)\n",
    "worst_df = df.sort_values(by=['Test Acc@1'], ascending=True).head(k).reset_index(drop=True)\n",
    "\n",
    "print(len(best_df), len(worst_df))\n",
    "best_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_vector = np.array([0]*12)\n",
    "\n",
    "for i in range(len(best_df)):\n",
    "    vector_path = best_df['Vector Path'][i]\n",
    "    vector = np.load(vector_path)\n",
    "    best_vector += vector\n",
    "\n",
    "worst_vector = np.array([0]*12)\n",
    "\n",
    "for i in range(len(worst_df)):\n",
    "    vector_path = worst_df['Vector Path'][i]\n",
    "    vector = np.load(vector_path)\n",
    "    worst_vector += vector\n",
    "\n",
    "best_vector, worst_vector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many times was each block selected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See which blocks were activated the maximum number of times\n",
    "\n",
    "sum_vec = np.array([0]*12)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    vec = np.load(df['Vector Path'][i])\n",
    "    sum_vec += vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(sum_vec))\n",
    "\n",
    "plt.figsize=(20, 10)\n",
    "# Plot the bar graph\n",
    "plt.bar(indices, sum_vec)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Block Index')\n",
    "plt.ylabel('Number of Times Trainable')\n",
    "plt.xticks(list(range(0,12)))\n",
    "plt.yticks(list(range(0, max(sum_vec)+1)))\n",
    "plt.title('Bar Plot of the number of times each attention block was activated (in 50 runs) in a ViT-Base Model.')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Random_Attention_Block_Tuning_{}.png\".format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(best_vector))\n",
    "\n",
    "plt.figsize=(20, 10)\n",
    "# Plot the bar graph\n",
    "plt.bar(indices, best_vector, label='Best')\n",
    "plt.bar(indices, worst_vector, label='Worst')\n",
    "plt.legend()\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Block Index')\n",
    "plt.ylabel('Block Selection Count')\n",
    "plt.xticks(list(range(0,12)))\n",
    "plt.yticks(list(range(0, max(best_vector)+1)))\n",
    "plt.title('Comparing the attention block selection frequency for best and worst performing vectors.')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Selection_Comparison_{}.png\".format(dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMDG Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'smdg'\n",
    "base_path = '/home/co-dutt1/rds/hpc-work/Layer-Masking/'\n",
    "csv = base_path + 'vit_base/' + dataset + '/tune_attention_blocks_random_vit_base_0.0001.csv'\n",
    "\n",
    "df = pd.read_csv(csv)\n",
    "#df['Vector Path'] = df['Vector Path'].apply(lambda x: os.path.join(base_path, x.split('/')[-1]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc = df['Test Acc@1'].mean()\n",
    "std_acc = df['Test Acc@1'].std()\n",
    "max_acc = df['Test Acc@1'].max()\n",
    "min_acc = df['Test Acc@1'].min()\n",
    "avg_train_percent = df['Train Percent'].mean()\n",
    "best_train_percent = df[df['Test Acc@1'] == max_acc]['Train Percent'].values[0]\n",
    "diff = max_acc - min_acc\n",
    "\n",
    "print(\"Mean Acc: \", mean_acc)\n",
    "print(\"Std Acc: \", std_acc)\n",
    "print(\"Max Acc: \", max_acc)\n",
    "print(\"Min Acc: \", min_acc)\n",
    "print(\"Avg Train Percent: \", avg_train_percent)\n",
    "print(\"Best Performance Train Percent: \", best_train_percent)\n",
    "print(\"Difference (Max, Min): \", diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "best_df = df.sort_values(by=['Test Acc@1'], ascending=False).head(k).reset_index(drop=True)\n",
    "worst_df = df.sort_values(by=['Test Acc@1'], ascending=True).head(k).reset_index(drop=True)\n",
    "\n",
    "print(len(best_df), len(worst_df))\n",
    "best_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_vector = np.array([0]*12)\n",
    "\n",
    "for i in range(len(best_df)):\n",
    "    vector_path = best_df['Vector Path'][i]\n",
    "    vector = np.load(vector_path)\n",
    "    best_vector += vector\n",
    "\n",
    "worst_vector = np.array([0]*12)\n",
    "\n",
    "for i in range(len(worst_df)):\n",
    "    vector_path = worst_df['Vector Path'][i]\n",
    "    vector = np.load(vector_path)\n",
    "    worst_vector += vector\n",
    "\n",
    "best_vector, worst_vector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many times was each block selected?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See which blocks were activated the maximum number of times\n",
    "\n",
    "sum_vec = np.array([0]*12)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    vec = np.load(df['Vector Path'][i])\n",
    "    sum_vec += vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(sum_vec))\n",
    "\n",
    "plt.figsize=(20, 10)\n",
    "# Plot the bar graph\n",
    "plt.bar(indices, sum_vec)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Block Index')\n",
    "plt.ylabel('Number of Times Trainable')\n",
    "plt.xticks(list(range(0,12)))\n",
    "plt.yticks(list(range(0, max(sum_vec)+1)))\n",
    "plt.title('Bar Plot of the number of times each attention block was activated (in 50 runs) in a ViT-Base Model.')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Random_Attention_Block_Tuning_{}.png\".format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(best_vector))\n",
    "\n",
    "plt.figsize=(20, 10)\n",
    "# Plot the bar graph\n",
    "plt.bar(indices, best_vector, label='Best')\n",
    "plt.bar(indices, worst_vector, label='Worst')\n",
    "plt.legend()\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Block Index')\n",
    "plt.ylabel('Block Selection Count')\n",
    "plt.xticks(list(range(0,12)))\n",
    "plt.yticks(list(range(0, max(best_vector)+1)))\n",
    "plt.title('Comparing the attention block selection frequency for best and worst performing vectors.')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Selection_Comparison_{}.png\".format(dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HAM10000 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'HAM10000'\n",
    "base_path = '/home/co-dutt1/rds/hpc-work/Layer-Masking/'\n",
    "vector_path = '/home/co-dutt1/rds/hpc-work/Layer-Masking/saved_vectors/vit_base/HAM10000/tune_attention_blocks_random_0.0001/'\n",
    "csv = base_path + 'vit_base/' + dataset + '/tune_attention_blocks_random_vit_base_0.0001.csv'\n",
    "\n",
    "df = pd.read_csv(csv)\n",
    "df['Vector Path'] = df['Vector Path'].apply(lambda x: os.path.join(vector_path, x.split('/')[-1]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc = df['Test Acc@1'].mean()\n",
    "std_acc = df['Test Acc@1'].std()\n",
    "max_acc = df['Test Acc@1'].max()\n",
    "min_acc = df['Test Acc@1'].min()\n",
    "avg_train_percent = df['Train Percent'].mean()\n",
    "best_train_percent = df[df['Test Acc@1'] == max_acc]['Train Percent'].values[0]\n",
    "diff = max_acc - min_acc\n",
    "\n",
    "print(\"Mean Acc: \", mean_acc)\n",
    "print(\"Std Acc: \", std_acc)\n",
    "print(\"Max Acc: \", max_acc)\n",
    "print(\"Min Acc: \", min_acc)\n",
    "print(\"Avg Train Percent: \", avg_train_percent)\n",
    "print(\"Best train percent: \", best_train_percent)\n",
    "print(\"Difference (Max, Min): \", diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "best_df = df.sort_values(by=['Test Acc@1'], ascending=False).head(k).reset_index(drop=True)\n",
    "worst_df = df.sort_values(by=['Test Acc@1'], ascending=True).head(k).reset_index(drop=True)\n",
    "\n",
    "print(len(best_df), len(worst_df))\n",
    "worst_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_vector = np.array([0]*12)\n",
    "\n",
    "for i in range(len(best_df)):\n",
    "    vector_path = best_df['Vector Path'][i]\n",
    "    vector = np.load(vector_path)\n",
    "    best_vector += vector\n",
    "\n",
    "worst_vector = np.array([0]*12)\n",
    "\n",
    "for i in range(len(worst_df)):\n",
    "    vector_path = worst_df['Vector Path'][i]\n",
    "    vector = np.load(vector_path)\n",
    "    worst_vector += vector\n",
    "\n",
    "best_vector, worst_vector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many times was each block selected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See which blocks were activated the maximum number of times\n",
    "\n",
    "sum_vec = np.array([0]*12)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    vec = np.load(df['Vector Path'][i])\n",
    "    sum_vec += vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(sum_vec))\n",
    "\n",
    "plt.figsize=(20, 10)\n",
    "# Plot the bar graph\n",
    "plt.bar(indices, sum_vec)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Block Index')\n",
    "plt.ylabel('Number of Times Trainable')\n",
    "plt.xticks(list(range(0,12)))\n",
    "plt.yticks(list(range(0, max(sum_vec)+1)))\n",
    "plt.title('Bar Plot of the number of times each attention block was activated (in 50 runs) in a ViT-Base Model.')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Random_Attention_Block_Tuning_{}.png\".format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(best_vector))\n",
    "\n",
    "plt.figsize=(20, 10)\n",
    "# Plot the bar graph\n",
    "plt.bar(indices, best_vector, label='Best')\n",
    "plt.bar(indices, worst_vector, label='Worst')\n",
    "plt.legend()\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Block Index')\n",
    "plt.ylabel('Block Selection Count')\n",
    "plt.xticks(list(range(0,12)))\n",
    "plt.yticks(list(range(0, max(best_vector)+1)))\n",
    "plt.title('Comparing the attention block selection frequency for best and worst performing vectors.')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Selection_Comparison_{}.png\".format(dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'CIFAR10'\n",
    "base_path = '/home/co-dutt1/rds/hpc-work/Layer-Masking/'\n",
    "csv = base_path + 'vit_base/' + dataset + '/tune_attention_blocks_random_vit_base_0.0001.csv'\n",
    "\n",
    "df = pd.read_csv(csv)\n",
    "#df['Vector Path'] = df['Vector Path'].apply(lambda x: os.path.join(base_path, x.split('/')[-1]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc = df['Test Acc@1'].mean()\n",
    "std_acc = df['Test Acc@1'].std()\n",
    "max_acc = df['Test Acc@1'].max()\n",
    "min_acc = df['Test Acc@1'].min()\n",
    "avg_train_percent = df['Train Percent'].mean()\n",
    "best_train_percent = df[df['Test Acc@1'] == max_acc]['Train Percent'].values[0]\n",
    "diff = max_acc - min_acc\n",
    "\n",
    "print(\"Mean Acc: \", mean_acc)\n",
    "print(\"Std Acc: \", std_acc)\n",
    "print(\"Max Acc: \", max_acc)\n",
    "print(\"Min Acc: \", min_acc)\n",
    "print(\"Avg Train Percent: \", avg_train_percent)\n",
    "print(\"Best train percent: \", best_train_percent)\n",
    "print(\"Difference (Max, Min): \", diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "best_df = df.sort_values(by=['Test Acc@1'], ascending=False).head(k).reset_index(drop=True)\n",
    "worst_df = df.sort_values(by=['Test Acc@1'], ascending=True).head(k).reset_index(drop=True)\n",
    "\n",
    "print(len(best_df), len(worst_df))\n",
    "worst_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_vector = np.array([0]*12)\n",
    "\n",
    "for i in range(len(best_df)):\n",
    "    vector_path = best_df['Vector Path'][i]\n",
    "    vector = np.load(vector_path)\n",
    "    best_vector += vector\n",
    "\n",
    "worst_vector = np.array([0]*12)\n",
    "\n",
    "for i in range(len(worst_df)):\n",
    "    vector_path = worst_df['Vector Path'][i]\n",
    "    vector = np.load(vector_path)\n",
    "    worst_vector += vector\n",
    "\n",
    "best_vector, worst_vector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many times was each block selected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See which blocks were activated the maximum number of times\n",
    "\n",
    "sum_vec = np.array([0]*12)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    vec = np.load(df['Vector Path'][i])\n",
    "    sum_vec += vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(sum_vec))\n",
    "\n",
    "plt.figsize=(20, 10)\n",
    "# Plot the bar graph\n",
    "plt.bar(indices, sum_vec)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Block Index')\n",
    "plt.ylabel('Number of Times Trainable')\n",
    "plt.xticks(list(range(0,12)))\n",
    "plt.yticks(list(range(0, max(sum_vec)+1)))\n",
    "plt.title('Bar Plot of the number of times each attention block was activated (in 50 runs) in a ViT-Base Model.')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Random_Attention_Block_Tuning_{}.png\".format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(best_vector))\n",
    "\n",
    "plt.figsize=(20, 10)\n",
    "# Plot the bar graph\n",
    "plt.bar(indices, best_vector, label='Best')\n",
    "plt.bar(indices, worst_vector, label='Worst')\n",
    "plt.legend()\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Block Index')\n",
    "plt.ylabel('Block Selection Count')\n",
    "plt.xticks(list(range(0,12)))\n",
    "plt.yticks(list(range(0, max(best_vector)+1)))\n",
    "plt.title('Comparing the attention block selection frequency for best and worst performing vectors.')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Selection_Comparison_{}.png\".format(dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retinopathy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'retinopathy'\n",
    "base_path = '/home/co-dutt1/rds/hpc-work/Layer-Masking/'\n",
    "csv = base_path + 'vit_base/' + dataset + '/tune_attention_blocks_random_vit_base_0.0001.csv'\n",
    "\n",
    "df = pd.read_csv(csv)\n",
    "#df['Vector Path'] = df['Vector Path'].apply(lambda x: os.path.join(base_path, x.split('/')[-1]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc = df['Test Acc@1'].mean()\n",
    "std_acc = df['Test Acc@1'].std()\n",
    "max_acc = df['Test Acc@1'].max()\n",
    "min_acc = df['Test Acc@1'].min()\n",
    "avg_train_percent = df['Train Percent'].mean()\n",
    "best_train_percent = df[df['Test Acc@1'] == max_acc]['Train Percent'].values[0]\n",
    "diff = max_acc - min_acc\n",
    "\n",
    "print(\"Mean Acc: \", mean_acc)\n",
    "print(\"Std Acc: \", std_acc)\n",
    "print(\"Max Acc: \", max_acc)\n",
    "print(\"Min Acc: \", min_acc)\n",
    "print(\"Avg Train Percent: \", avg_train_percent)\n",
    "print(\"Best Train Percent: \", best_train_percent)\n",
    "print(\"Difference (Max, Min): \", diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10\n",
    "best_df = df.sort_values(by=['Test Acc@1'], ascending=False).head(k).reset_index(drop=True)\n",
    "worst_df = df.sort_values(by=['Test Acc@1'], ascending=True).head(k).reset_index(drop=True)\n",
    "\n",
    "print(len(best_df), len(worst_df))\n",
    "worst_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_vector = np.array([0]*12)\n",
    "\n",
    "for i in range(len(best_df)):\n",
    "    vector_path = best_df['Vector Path'][i]\n",
    "    vector = np.load(vector_path)\n",
    "    best_vector += vector\n",
    "\n",
    "worst_vector = np.array([0]*12)\n",
    "\n",
    "for i in range(len(worst_df)):\n",
    "    vector_path = worst_df['Vector Path'][i]\n",
    "    vector = np.load(vector_path)\n",
    "    worst_vector += vector\n",
    "\n",
    "best_vector, worst_vector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many times was each block selected?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See which blocks were activated the maximum number of times\n",
    "\n",
    "sum_vec = np.array([0]*12)\n",
    "\n",
    "for i in range(len(df)):\n",
    "    vec = np.load(df['Vector Path'][i])\n",
    "    sum_vec += vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(sum_vec))\n",
    "\n",
    "plt.figsize=(20, 10)\n",
    "# Plot the bar graph\n",
    "plt.bar(indices, sum_vec)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Block Index')\n",
    "plt.ylabel('Number of Times Trainable')\n",
    "plt.xticks(list(range(0,12)))\n",
    "plt.yticks(list(range(0, max(sum_vec)+1)))\n",
    "plt.title('Bar Plot of the number of times each attention block was activated (in 50 runs) in a ViT-Base Model.')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Random_Attention_Block_Tuning_{}.png\".format(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.arange(len(best_vector))\n",
    "\n",
    "plt.figsize=(20, 10)\n",
    "# Plot the bar graph\n",
    "plt.bar(indices, best_vector, label='Best')\n",
    "plt.bar(indices, worst_vector, label='Worst')\n",
    "plt.legend()\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Block Index')\n",
    "plt.ylabel('Block Selection Count')\n",
    "plt.xticks(list(range(0,12)))\n",
    "plt.yticks(list(range(0, max(best_vector)+1)))\n",
    "plt.title('Comparing the attention block selection frequency for best and worst performing vectors.')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Selection_Comparison_{}.png\".format(dataset))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CIFAR100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pneumonia"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity b/w best performing vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/co-dutt1/rds/hpc-work/Layer-Masking/'\n",
    "\n",
    "dataset = 'breastUS'\n",
    "csv = base_path + 'vit_base/' + dataset + '/tune_attention_blocks_random_vit_base_0.0001.csv'\n",
    "df_breastUS = pd.read_csv(csv)\n",
    "\n",
    "dataset = 'fitzpatrick'\n",
    "csv = base_path + 'vit_base/' + dataset + '/tune_attention_blocks_random_vit_base_0.0001.csv'\n",
    "df_fitzpatrick = pd.read_csv(csv)\n",
    "\n",
    "dataset = 'HAM10000'\n",
    "vector_path = '/home/co-dutt1/rds/hpc-work/Layer-Masking/saved_vectors/vit_base/HAM10000/tune_attention_blocks_random_0.0001/'\n",
    "csv = base_path + 'vit_base/' + dataset + '/tune_attention_blocks_random_vit_base_0.0001.csv'\n",
    "df_ham10k = pd.read_csv(csv)\n",
    "df_ham10k['Vector Path'] = df_ham10k['Vector Path'].apply(lambda x: os.path.join(vector_path, x.split('/')[-1]))\n",
    "\n",
    "dataset = 'smdg'\n",
    "csv = base_path + 'vit_base/' + dataset + '/tune_attention_blocks_random_vit_base_0.0001.csv'\n",
    "df_smdg = pd.read_csv(csv)\n",
    "\n",
    "dataset = 'retinopathy'\n",
    "csv = base_path + 'vit_base/' + dataset + '/tune_attention_blocks_random_vit_base_0.0001.csv'\n",
    "df_retinopathy = pd.read_csv(csv)\n",
    "\n",
    "dataset = 'CIFAR10'\n",
    "csv = base_path + 'vit_base/' + dataset + '/tune_attention_blocks_random_vit_base_0.0001.csv'\n",
    "df_CIFAR10 = pd.read_csv(csv)\n",
    "\n",
    "dataset = 'CIFAR100'\n",
    "csv = base_path + 'vit_base/' + dataset + '/tune_attention_blocks_random_vit_base_0.0001.csv'\n",
    "df_CIFAR100 = pd.read_csv(csv)\n",
    "\n",
    "dataset = 'pneumonia'\n",
    "csv = base_path + 'vit_base/' + dataset + '/tune_attention_blocks_random_vit_base_0.0001.csv'\n",
    "df_pneumonia = pd.read_csv(csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort all the dataframes\n",
    "\n",
    "k = 10\n",
    "# best_df_breastUS = df_breastUS.sort_values(by=['Test Acc@1'], ascending=False).head(k).reset_index(drop=True)\n",
    "# worst_df_breastUS = df_breastUS.sort_values(by=['Test Acc@1'], ascending=True).head(k).reset_index(drop=True)\n",
    "\n",
    "# best_df_fitzpatrick = df_fitzpatrick.sort_values(by=['Test Acc@1'], ascending=False).head(k).reset_index(drop=True)\n",
    "# worst_df_fitzpatrick = df_fitzpatrick.sort_values(by=['Test Acc@1'], ascending=True).head(k).reset_index(drop=True)\n",
    "\n",
    "# best_df_ham10k = df_ham10k.sort_values(by=['Test Acc@1'], ascending=False).head(k).reset_index(drop=True)\n",
    "# worst_df_ham10k = df_ham10k.sort_values(by=['Test Acc@1'], ascending=True).head(k).reset_index(drop=True)\n",
    "\n",
    "# best_df_smdg = df_smdg.sort_values(by=['Test Acc@1'], ascending=False).head(k).reset_index(drop=True)\n",
    "# worst_df_smdg = df_smdg.sort_values(by=['Test Acc@1'], ascending=True).head(k).reset_index(drop=True)\n",
    "\n",
    "# best_df_retinopathy = df_retinopathy.sort_values(by=['Test Acc@1'], ascending=False).head(k).reset_index(drop=True)\n",
    "# worst_df_retinopathy = df_retinopathy.sort_values(by=['Test Acc@1'], ascending=True).head(k).reset_index(drop=True)\n",
    "\n",
    "# best_df_CIFAR10 = df_CIFAR10.sort_values(by=['Test Acc@1'], ascending=False).head(k).reset_index(drop=True)\n",
    "# worst_df_CIFAR10 = df_CIFAR10.sort_values(by=['Test Acc@1'], ascending=True).head(k).reset_index(drop=True)\n",
    "\n",
    "# best_df_CIFAR100 = df_CIFAR100.sort_values(by=['Test Acc@1'], ascending=False).head(k).reset_index(drop=True)\n",
    "# worst_df_CIFAR100 = df_CIFAR100.sort_values(by=['Test Acc@1'], ascending=True).head(k).reset_index(drop=True)\n",
    "\n",
    "# best_df_pneumonia = df_pneumonia.sort_values(by=['Test Acc@1'], ascending=False).head(k).reset_index(drop=True)\n",
    "# worst_df_pneumonia = df_pneumonia.sort_values(by=['Test Acc@1'], ascending=True).head(k).reset_index(drop=True)\n",
    "\n",
    "all_datasets = [df_breastUS, df_fitzpatrick, df_ham10k, df_smdg, df_retinopathy, df_CIFAR10, df_CIFAR100, df_pneumonia]\n",
    "_best = np.array([0]*12)\n",
    "_worst = np.array([0]*12)\n",
    "\n",
    "for df in all_datasets:\n",
    "    best_vector, worst_vector = create_best_worst_vectors(df)\n",
    "    _best += best_vector\n",
    "    _worst += worst_vector\n",
    "\n",
    "_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating best and worst vectors for each dataset\n",
    "\n",
    "indices = np.arange(len(_best))\n",
    "\n",
    "plt.figsize=(20, 15)\n",
    "# Plot the bar graph\n",
    "plt.bar(indices, _best, label='Best')\n",
    "plt.bar(indices, _worst, label='Worst')\n",
    "plt.legend()\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Block Index')\n",
    "plt.ylabel('Block Selection Count')\n",
    "plt.xticks(list(range(0,12)))\n",
    "plt.yticks(list(range(0, max(_best)+1, 4)))\n",
    "plt.title('Comparing the attention block selection frequency for best and worst performing vectors.')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"vit-b_best_worst_block_level.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_acc_breastUS = df_breastUS['Test Acc@1'].max()\n",
    "max_acc_fitzpatrick = df_fitzpatrick['Test Acc@1'].max()\n",
    "max_acc_ham10k = df_ham10k['Test Acc@1'].max()\n",
    "max_acc_smdg = df_smdg['Test Acc@1'].max()\n",
    "max_acc_retinopathy = df_retinopathy['Test Acc@1'].max()\n",
    "max_acc_CIFAR10 = df_CIFAR10['Test Acc@1'].max()\n",
    "max_acc_CIFAR100 = df_CIFAR100['Test Acc@1'].max()\n",
    "max_acc_pneumonia = df_pneumonia['Test Acc@1'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_vector_breastUS = np.load(df_breastUS[df_breastUS['Test Acc@1'] == max_acc_breastUS]['Vector Path'].values[0])\n",
    "best_vector_fitzpatrick = np.load(df_fitzpatrick[df_fitzpatrick['Test Acc@1'] == max_acc_fitzpatrick]['Vector Path'].values[0])\n",
    "best_vector_ham10k = np.load(df_ham10k[df_ham10k['Test Acc@1'] == max_acc_ham10k]['Vector Path'].values[0])\n",
    "best_vector_smdg = np.load(df_smdg[df_smdg['Test Acc@1'] == max_acc_smdg]['Vector Path'].values[0])\n",
    "best_vector_retinopathy = np.load(df_retinopathy[df_retinopathy['Test Acc@1'] == max_acc_retinopathy]['Vector Path'].values[0])\n",
    "best_vector_CIFAR10 = np.load(df_CIFAR10[df_CIFAR10['Test Acc@1'] == max_acc_CIFAR10]['Vector Path'].values[0])\n",
    "best_vector_CIFAR100 = np.load(df_CIFAR100[df_CIFAR100['Test Acc@1'] == max_acc_CIFAR100]['Vector Path'].values[0])\n",
    "best_vector_pneumonia = np.load(df_pneumonia[df_pneumonia['Test Acc@1'] == max_acc_pneumonia]['Vector Path'].values[0])\n",
    "\n",
    "#all_best_vectors = [best_vector_breastUS, best_vector_fitzpatrick, best_vector_ham10k, best_vector_smdg, best_vector_retinopathy, best_vector_CIFAR10]\n",
    "all_best_vectors = [best_vector_breastUS, best_vector_fitzpatrick, best_vector_ham10k, best_vector_smdg, best_vector_retinopathy, best_vector_CIFAR10, best_vector_CIFAR100, best_vector_pneumonia]\n",
    "\n",
    "vectors = []\n",
    "for vector in all_best_vectors:\n",
    "    vectors.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vectors = len(vectors)\n",
    "similarity_matrix = np.zeros((num_vectors, num_vectors))\n",
    "\n",
    "for i in range(num_vectors):\n",
    "    for j in range(num_vectors):\n",
    "        cos_dist = distance.cosine(vectors[i], vectors[j])\n",
    "        cos_similarity = 1 - cos_dist\n",
    "        similarity_matrix[i, j] = cos_similarity\n",
    "        print(\"Cosine Sim b/w vector {} and {}: \".format(str(i), str(j)), cos_similarity)\n",
    "\n",
    "similarity_df = pd.DataFrame(similarity_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a confusion matrix using seaborn and save it as a figure\n",
    "tuning_method = 'tune_attention_blocks_random'\n",
    "top_k = 10\n",
    "datasets = ['BreastUS', 'Fitzpatrick', 'HAM10000', 'SMDG', 'Retinopathy', 'CIFAR10']\n",
    "pos = [0.5,1.5,2.5,3.5,4.5,5.5]\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "sns.heatmap(similarity_df, annot=True, fmt='.2f', cmap='coolwarm')\n",
    "plt.xlabel(\"Vectors\")\n",
    "plt.ylabel(\"Vectors\")\n",
    "plt.xticks(pos, datasets)\n",
    "plt.yticks(pos, datasets)\n",
    "plt.title(\"Cos-Sim b/w best vectors\")\n",
    "plt.savefig('cosine_similarity_cm_{}_top_{}.png'.format(tuning_method, str(top_k))) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
